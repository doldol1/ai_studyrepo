{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "# glob 결과 숫자 오름차순으로 정리해주는 라이브러리, 기능적으로 필요하지 않았음을 깨달았으나 \n",
    "# 정렬 작업이 유지보수를 가정했을 때 충분히 의미 있다고 생각해서 그냥 놔두기로 함\n",
    "import natsort \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform을 적용한 커스텀 데이터셋\n",
    "# 무조건 torch.utils.data.Dataset을 상속받아야 한다.\n",
    "class cnd_data(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, train=True, transforms=None):\n",
    "\n",
    "        self.train=train\n",
    "        self.transforms=transforms\n",
    "\n",
    "        # cat, dog 경로 설정\n",
    "        self.cat_img_path=os.path.join(file_path, 'data\\kagglecatsanddogs\\PetImages\\Cat')\n",
    "        self.dog_img_path=os.path.join(file_path, 'data\\kagglecatsanddogs\\PetImages\\Dog')\n",
    "        \n",
    "        # cat, dog 이미지 목록 불러오기\n",
    "        self.cat_list=natsort.natsorted(glob.glob(self.cat_img_path + '/*.jpg'))\n",
    "        self.dog_list=natsort.natsorted(glob.glob(self.dog_img_path + '/*.jpg'))\n",
    " \n",
    "        # cat, dog 이미지 list 및 label 지정하기, 0은 cat이고, 1은 dog이다\n",
    "        # cat, dog 각각 12500개의 이미지가 존재하며, 각각 12000개는 train, 500개는 test에 사용된다\n",
    "        if self.train==True:\n",
    "            self.imgn_list=self.cat_list[:12000]+self.dog_list[:12000]\n",
    "            self.img_label=[0]*12000+[1]*12000\n",
    "\n",
    "        else:\n",
    "            self.imgn_list=self.cat_list[12000:]+self.dog_list[12000:]\n",
    "            self.img_label=[0]*500+[1]*500\n",
    "\n",
    "        # 한번에 모든 이미지를 메모리에 올리고 싶었지만 공간 부족으로 불가\n",
    "        # getitem쪽에 올렸다.\n",
    "\n",
    "\n",
    "    # __len__()은 데이터쌍의 개수를 의미한다.\n",
    "    # 아마 __len__의 크기를 기준으로 Dataloader에서 batch 묶음의 수를 결정하고 \n",
    "    # __len__만큼의 데이터쌍을 가져오는 것 같다.\n",
    "    def __len__(self):\n",
    "        return len(self.img_label)\n",
    "\n",
    "    # __getitem__()은 하나의 데이터쌍(보통 데이터, 레이블)을 가져오는데 사용된다.\n",
    "    # __getitem__출력시 한 쌍의 데이터가 아니라 한 batch만큼을 한번에 불러오는 방식으로 짜고 싶었지만\n",
    "    # (만약 그렇게 한다면 Dataloader에서 불러온 다음 중첩 for문을 사용하여 사용하게 될 것이다.)\n",
    "    # 처음으로 짜는 커스텀 데이터셋이기 때문에 한 쌍의 데이터를 가져올 때마다\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # 원 데이터는 cat과 dog 폴더로 나뉘어 있으며, 각각 0~12499까지 숫자가 파일 이름으로 사용된다.\n",
    "        # 또한, train은 0~11999, test는 12000~12499 를 파일 이름으로 사용한다.\n",
    "        # train 기준 실존하는 imgn_list의 index는 0~23999까지 사용하게 되므로, \n",
    "        # 0~11999 idx의 경우 cat폴더에서 가져와야 하며,\n",
    "        # 12000~23999 idx의 경우 dog 폴더에서 가져와야 한다.(당연히 dog폴더의 train이미지는 0~11999이므로 숫자 변환도 필요하다)\n",
    "        # 라고 처음에는 생각해 왔지만 헛생각이었다... 어차피 인덱스와 이에 해당하는 이미지 경로는 연결되어 있으니 추가적인 조치를 취하지 않고도\n",
    "        # 문제를 해결할 수 있다. \n",
    "        image_data=Image.open(self.imgn_list[idx])\n",
    "\n",
    "        print('변환 전 사이즈:',np.array(image_data).shape)\n",
    "        \n",
    "        if self.transforms:\n",
    "            sample=self.transforms(image_data)\n",
    "\n",
    "        # 이미지에서 channel이 3이 아닌 경우\n",
    "        if sample.size()[0] != 3:\n",
    "            print(self.imgn_list[idx])\n",
    "            print('변환 사이즈:', sample.size())\n",
    "            \n",
    "            # sample=sample.expand(3, -1, -1)\n",
    "            # print(sample.size())\n",
    "\n",
    "        return sample, self.img_label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정, py파일로 변환시 경로는 변경되어야 한다.\n",
    "path=os.path.abspath('../')\n",
    "\n",
    "# Resize: 크기를 224, 224로 맞춘다\n",
    "# ToTensor: 데이터 타입을 Tensor로 만든다. Tensor의 원소는 0~1로 정해진다.(https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)\n",
    "# custom으로 transform를 작성하는 것도 가능하다.\n",
    "transforms=transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_train=cnd_data(file_path=path, train=True, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_dataloader=DataLoader(cnd_train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 96.29\n",
      "Params size (MB): 83.15\n",
      "Estimated Total Size (MB): 180.01\n",
      "----------------------------------------------------------------\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# resnet34나 50이나 조금씩 원문에서 주장하는 model을 수정한 듯한 흔적이 보인다.\n",
    "# 하지만 지금은 resnet 원문의 것을 구현하는 입장이기 때문에\n",
    "# 모델 참조를 하다 원문과 다른 부분이 있다면 무시하고 원문대로 한다.\n",
    "resnet34_preset=models.resnet34()\n",
    "summary(resnet34_preset, input_size=(3, 224, 224))\n",
    "print(resnet34_preset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet50_preset=models.resnet50()\n",
    "summary(resnet50_preset, input_size=(3, 224, 224))\n",
    "print(resnet50_preset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의할 때는 무조건 torch.nn.Module을 상속받아야 한다.\n",
    "# block은 short connection이 있는 최소 단위이며 \n",
    "# group은 동일한 block 형성 패턴(논문 table 1의 conv2_x, conv3_x)을 의미한다.\n",
    "class ResNet_compat(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape=(3, 224, 224),\n",
    "                 blocks_in_model=[3, 4, 6, 3],\n",
    "                 layers_in_block=[2, 2, 2, 2],\n",
    "                 kernel_sizes=[(3,3), (3,3), (3,3), (3,3)],\n",
    "                 channel_sizes=[(64,64), (128,128), (256,256), (512,512)],\n",
    "                 class_size=2,\n",
    "                 is_plain=False):\n",
    "\n",
    "        super(ResNet_compat, self).__init__()\n",
    "\n",
    "        self.input_shape=input_shape\n",
    "        self.blocks_in_model=blocks_in_model\n",
    "        self.layers_in_block=layers_in_block\n",
    "        self.kernel_sizes=kernel_sizes\n",
    "        self.channel_sizes=channel_sizes\n",
    "        self.class_size=class_size\n",
    "        self.is_plain=is_plain\n",
    "\n",
    "\n",
    "        # pytorch에도 padding='same'이라는 옵션은 존재하지만, stride=1일\n",
    "        # 경우만 사용 가능하다.\n",
    "        # 아래 코드는 (W-F+2P)/S + 1 공식 적용한 코드로\n",
    "        # 계산 결과가 소수점이 나오지만, pytorch에서 사용하는 resnet이 이렇게 설정하였기 때문에\n",
    "        # 똑같이 진행한다. \n",
    "        \n",
    "        # conv1+conv2 maxpooling\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(), # 왜 그런지 모르겠지만 preset에는 inplace=True(default: False)\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # conv2(maxpooling은 제외), short connection은 구현부에서 구현\n",
    "        \n",
    "        self.block_forms=list()\n",
    "        for i in range(len(blocks_in_model)):\n",
    "            for j in range(blocks_in_model[i]):\n",
    "                \n",
    "                # i는 group, j는 block\n",
    "                if i==0 and j==0:\n",
    "                    inp_channel=64\n",
    "                elif i!=0 and j==0:\n",
    "                    inp_channel=channel_sizes[i-1][-1]\n",
    "                else:\n",
    "                    inp_channel=False\n",
    "\n",
    "                # # input_channel은 block의 맨 처음+group(group: block묶음)의 맨 처음인 경우만 사용됨\n",
    "                # self.block_forms.append(nn.Sequential(*self.build_block(\n",
    "                #     self.layers_in_block[i],\n",
    "                #     kernel_sizes=self.kernel_sizes[i],\n",
    "                #     channel_sizes=self.channel_sizes[i],\n",
    "                #     input_channel=inp_channel,\n",
    "                #     is_plain=False\n",
    "                # )))\n",
    "                # input_channel은 block의 맨 처음+group(group: block묶음)의 맨 처음인 경우만 사용됨\n",
    "                self.block_forms.append(self.build_block(\n",
    "                    self.layers_in_block[i],\n",
    "                    kernel_sizes=self.kernel_sizes[i],\n",
    "                    channel_sizes=self.channel_sizes[i],\n",
    "                    input_channel=inp_channel,\n",
    "                    is_plain=False\n",
    "                ))\n",
    "\n",
    "\n",
    "\n",
    "        # summary가 안 먹혀서 새로 짠 코드\n",
    "        # self.model_body=nn.Sequential(*self.block_forms)\n",
    "        \n",
    "        # 선언을 하려고 하면 추가 입력이 필요해서 forward에 설정해야 하는 상황...\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.end_avg2d=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.end_linear=nn.Linear(in_features=self.channel_sizes[-1][-1], out_features=2, bias=True)\n",
    "        # self.end_linear=nn.Linear(in_features=512*int(channel_sizes[-1][0]/channel_sizes[-1][-1]), out_features=2, bias=True)\n",
    "        # self.end_linear=nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "        self.end_softmax=nn.Softmax(-1)\n",
    "    \n",
    "    # input_channel은 block의 맨 처음+group(group: block묶음)의 맨 처음인 경우만 사용됨\n",
    "    def build_block(self, layers, kernel_sizes, channel_sizes, input_channel, is_plain=False):\n",
    "        \n",
    "        full_block=[]\n",
    "        for i in range(layers):\n",
    "            if kernel_sizes[i]!= 1:\n",
    "                layer_padding=(1,1)\n",
    "            else:\n",
    "                layer_padding=(0,0)\n",
    "\n",
    "            if input_channel and i==0:\n",
    "                if input_channel != channel_sizes[i]:\n",
    "                    f_stride=2\n",
    "                else:\n",
    "                    f_stride=1\n",
    "                full_block.append(nn.Conv2d(in_channels=input_channel, \n",
    "                                            out_channels=channel_sizes[i], \n",
    "                                            kernel_size=kernel_sizes[i],\n",
    "                                            padding=layer_padding,\n",
    "                                            stride=f_stride,\n",
    "                                            bias=False\n",
    "                                            ))\n",
    "            else:\n",
    "                # 50이상은 channel이 일시적으로 늘어나도 feature map의 크기가 그대로임음 명심할 것\n",
    "                # padding만 어떻게 할지 고민해보자... kernel_size가 1일 때는 패딩 제외?? 아니면 3일 때만 padding 1??\n",
    "                full_block.append(nn.Conv2d(in_channels=channel_sizes[i-1],\n",
    "                                            out_channels=channel_sizes[i],\n",
    "                                            kernel_size=kernel_sizes[i],\n",
    "                                            padding=layer_padding,\n",
    "                                            bias=False\n",
    "                                            ))\n",
    "            # batch_normalization\n",
    "            full_block.append(nn.BatchNorm2d(channel_sizes[i], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "\n",
    "            # short connection은 구현부에서 만들기 때문에 block의 마지막 layer가 아니라면 relu 추가\n",
    "            # inplace 옵션이 있고, pre-model에서는 사용하긴 사용하지만 왜 사용하는지 모르겠어서 사용 안함\n",
    "            if i< layers-1:\n",
    "                full_block.append(nn.ReLU())\n",
    "\n",
    "        return nn.Sequential(*full_block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x=self.conv1(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # model body\n",
    "        for block in self.block_forms:\n",
    "            identity=x\n",
    "            x=block(x)\n",
    "\n",
    "            if block[0].in_channels != block[0].out_channels:\n",
    "                self.reduce=nn.Conv2d(\n",
    "                    block[0].in_channels,\n",
    "                    block[0].out_channels,\n",
    "                    kernel_size=(1,1),\n",
    "                    stride=2)\n",
    "                identity=self.reduce(identity)\n",
    "            \n",
    "            x+=identity\n",
    "            x=self.relu(x)\n",
    "\n",
    "        \n",
    "        # 끝단\n",
    "        x=self.end_avg2d(x)\n",
    "        x=torch.flatten(x, 1, -1)\n",
    "\n",
    "        # x현재 shape는 [2, 512, 1, 1]\n",
    "        x=self.end_linear(x)\n",
    "        x=self.end_softmax(x)\n",
    "       \n",
    "        return x\n",
    "\n",
    "        # return self.conv_temp(x)\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "              ReLU-5           [-1, 64, 56, 56]               0\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "              ReLU-8          [-1, 128, 28, 28]               0\n",
      "              ReLU-9          [-1, 128, 28, 28]               0\n",
      "             ReLU-10          [-1, 128, 28, 28]               0\n",
      "             ReLU-11          [-1, 128, 28, 28]               0\n",
      "             ReLU-12          [-1, 256, 14, 14]               0\n",
      "             ReLU-13          [-1, 256, 14, 14]               0\n",
      "             ReLU-14          [-1, 256, 14, 14]               0\n",
      "             ReLU-15          [-1, 256, 14, 14]               0\n",
      "             ReLU-16          [-1, 256, 14, 14]               0\n",
      "             ReLU-17          [-1, 256, 14, 14]               0\n",
      "             ReLU-18            [-1, 512, 7, 7]               0\n",
      "             ReLU-19            [-1, 512, 7, 7]               0\n",
      "             ReLU-20            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-21            [-1, 512, 1, 1]               0\n",
      "           Linear-22                    [-1, 2]           1,026\n",
      "          Softmax-23                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 10,562\n",
      "Trainable params: 10,562\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 30.44\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 31.05\n",
      "----------------------------------------------------------------\n",
      "ResNet_compat(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (end_avg2d): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (end_linear): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (end_softmax): Softmax(dim=-1)\n",
      "  (reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_model=ResNet_compat()\n",
    "summary(train_model, input_size=(3, 224, 224))\n",
    "print(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "\n",
    "loss_f= nn.CrossEntropyLoss()\n",
    "# train_model.parameters: 최적화할 대상의 파라미터\n",
    "# lr=learning_rate\n",
    "optimizer = torch.optim.SGD(train_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 전 사이즈: (259, 259, 3)\n",
      "변환 전 사이즈: (159, 82, 3)\n",
      "변환 전 사이즈: (409, 500, 3)\n",
      "변환 전 사이즈: (500, 285, 3)\n",
      "변환 전 사이즈: (488, 500, 3)\n",
      "변환 전 사이즈: (400, 267, 3)\n",
      "변환 전 사이즈: (378, 500, 3)\n",
      "변환 전 사이즈: (442, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (399, 385, 3)\n",
      "변환 전 사이즈: (239, 350, 3)\n",
      "변환 전 사이즈: (269, 500, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (349, 320, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 422, 3)\n",
      "변환 전 사이즈: (375, 490, 3)\n",
      "변환 전 사이즈: (200, 200, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (297, 360, 3)\n",
      "변환 전 사이즈: (500, 333, 3)\n",
      "변환 전 사이즈: (487, 358, 3)\n",
      "변환 전 사이즈: (448, 500, 3)\n",
      "변환 전 사이즈: (342, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (371, 500, 3)\n",
      "변환 전 사이즈: (338, 450, 3)\n",
      "변환 전 사이즈: (350, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (360, 480, 3)\n",
      "변환 전 사이즈: (500, 273, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (200, 183, 3)\n",
      "변환 전 사이즈: (417, 315, 3)\n",
      "변환 전 사이즈: (400, 384, 3)\n",
      "변환 전 사이즈: (295, 500, 3)\n",
      "변환 전 사이즈: (189, 220, 3)\n",
      "변환 전 사이즈: (276, 230, 3)\n",
      "변환 전 사이즈: (225, 300, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (239, 320, 3)\n",
      "변환 전 사이즈: (287, 287, 3)\n",
      "변환 전 사이즈: (466, 500, 3)\n",
      "변환 전 사이즈: (292, 361, 3)\n",
      "변환 전 사이즈: (459, 307, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (399, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (442, 396, 3)\n",
      "변환 전 사이즈: (469, 500, 3)\n",
      "변환 전 사이즈: (446, 289, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 433, 3)\n",
      "변환 전 사이즈: (500, 290, 3)\n",
      "변환 전 사이즈: (400, 438, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (438, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (457, 300, 3)\n",
      "변환 전 사이즈: (500, 304, 3)\n",
      "변환 전 사이즈: (300, 400, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (334, 500, 3)\n",
      "변환 전 사이즈: (257, 300, 3)\n",
      "변환 전 사이즈: (500, 345, 3)\n",
      "변환 전 사이즈: (372, 500, 3)\n",
      "변환 전 사이즈: (456, 368, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (243, 162, 3)\n",
      "변환 전 사이즈: (217, 400, 3)\n",
      "변환 전 사이즈: (204, 288, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (434, 500, 3)\n",
      "변환 전 사이즈: (287, 241, 3)\n",
      "변환 전 사이즈: (500, 464, 3)\n",
      "변환 전 사이즈: (270, 360, 3)\n",
      "변환 전 사이즈: (467, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (300, 400, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 463, 3)\n",
      "변환 전 사이즈: (321, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (200, 250, 3)\n",
      "변환 전 사이즈: (324, 432, 3)\n",
      "변환 전 사이즈: (300, 400, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (302, 479, 3)\n",
      "변환 전 사이즈: (296, 500, 3)\n",
      "변환 전 사이즈: (500, 464, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (463, 500, 3)\n",
      "변환 전 사이즈: (271, 250, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (468, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 496, 3)\n",
      "변환 전 사이즈: (500, 394, 3)\n",
      "변환 전 사이즈: (472, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (416, 500, 3)\n",
      "변환 전 사이즈: (410, 375, 3)\n",
      "변환 전 사이즈: (200, 200, 3)\n",
      "변환 전 사이즈: (400, 393, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (377, 374, 3)\n",
      "변환 전 사이즈: (376, 500, 3)\n",
      "변환 전 사이즈: (500, 357, 3)\n",
      "변환 전 사이즈: (197, 161, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (300, 400, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (322, 293, 3)\n",
      "변환 전 사이즈: (300, 225, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (65, 110, 3)\n",
      "변환 전 사이즈: (500, 276, 3)\n",
      "변환 전 사이즈: (335, 500, 3)\n",
      "변환 전 사이즈: (149, 192, 3)\n",
      "변환 전 사이즈: (482, 500, 3)\n",
      "변환 전 사이즈: (500, 388, 3)\n",
      "변환 전 사이즈: (500, 381, 3)\n",
      "변환 전 사이즈: (256, 384, 3)\n",
      "변환 전 사이즈: (328, 500, 3)\n",
      "변환 전 사이즈: (429, 500, 3)\n",
      "변환 전 사이즈: (396, 355, 3)\n",
      "변환 전 사이즈: (376, 500, 3)\n",
      "변환 전 사이즈: (456, 500, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (166, 221, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (400, 400, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 402, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 333, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 365, 3)\n",
      "변환 전 사이즈: (300, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (216, 288, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (358, 500, 3)\n",
      "변환 전 사이즈: (382, 500, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (500, 373, 3)\n",
      "변환 전 사이즈: (448, 479, 3)\n",
      "변환 전 사이즈: (400, 321, 3)\n",
      "변환 전 사이즈: (406, 355, 3)\n",
      "변환 전 사이즈: (386, 288, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (388, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (231, 350, 3)\n",
      "변환 전 사이즈: (369, 282, 3)\n",
      "변환 전 사이즈: (500, 411, 3)\n",
      "변환 전 사이즈: (411, 291, 3)\n",
      "변환 전 사이즈: (500, 429, 3)\n",
      "변환 전 사이즈: (500, 421, 3)\n",
      "변환 전 사이즈: (360, 480, 3)\n",
      "변환 전 사이즈: (500, 268, 3)\n",
      "변환 전 사이즈: (359, 500, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (378, 500, 3)\n",
      "변환 전 사이즈: (374, 499, 3)\n",
      "변환 전 사이즈: (353, 500, 3)\n",
      "변환 전 사이즈: (342, 380, 3)\n",
      "변환 전 사이즈: (310, 500, 3)\n",
      "변환 전 사이즈: (453, 500, 3)\n",
      "변환 전 사이즈: (200, 159, 3)\n",
      "변환 전 사이즈: (474, 288, 3)\n",
      "변환 전 사이즈: (318, 480, 3)\n",
      "변환 전 사이즈: (500, 498, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "Loss [1, 5](epoch, minibatch):  0.04153846740722656\n",
      "변환 전 사이즈: (457, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (258, 250, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (496, 500, 3)\n",
      "변환 전 사이즈: (500, 473, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (199, 300, 3)\n",
      "변환 전 사이즈: (294, 348, 3)\n",
      "변환 전 사이즈: (446, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 371, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (82, 90, 3)\n",
      "변환 전 사이즈: (148, 196, 3)\n",
      "변환 전 사이즈: (445, 500, 3)\n",
      "변환 전 사이즈: (250, 250, 3)\n",
      "변환 전 사이즈: (304, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (320, 322, 3)\n",
      "변환 전 사이즈: (500, 413, 3)\n",
      "변환 전 사이즈: (500, 333, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (480, 400, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (231, 180, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (303, 357, 3)\n",
      "변환 전 사이즈: (336, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (294, 295, 3)\n",
      "변환 전 사이즈: (288, 241, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (381, 407, 3)\n",
      "변환 전 사이즈: (430, 416, 3)\n",
      "변환 전 사이즈: (200, 250, 3)\n",
      "변환 전 사이즈: (216, 201, 3)\n",
      "변환 전 사이즈: (285, 385, 3)\n",
      "변환 전 사이즈: (200, 300, 3)\n",
      "변환 전 사이즈: (304, 392, 3)\n",
      "변환 전 사이즈: (357, 500, 3)\n",
      "변환 전 사이즈: (333, 403, 3)\n",
      "변환 전 사이즈: (252, 159, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (316, 500, 3)\n",
      "변환 전 사이즈: (446, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (170, 350, 3)\n",
      "변환 전 사이즈: (448, 500, 3)\n",
      "변환 전 사이즈: (500, 481, 3)\n",
      "변환 전 사이즈: (190, 151, 3)\n",
      "변환 전 사이즈: (500, 415, 3)\n",
      "변환 전 사이즈: (337, 400, 3)\n",
      "변환 전 사이즈: (113, 150, 3)\n",
      "변환 전 사이즈: (362, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (254, 400, 3)\n",
      "변환 전 사이즈: (245, 228, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (377, 500, 3)\n",
      "변환 전 사이즈: (252, 239, 3)\n",
      "변환 전 사이즈: (412, 473, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (353, 400, 3)\n",
      "변환 전 사이즈: (138, 178, 3)\n",
      "변환 전 사이즈: (500, 430, 3)\n",
      "변환 전 사이즈: (349, 239, 3)\n",
      "변환 전 사이즈: (500, 464, 3)\n",
      "변환 전 사이즈: (291, 154, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (271, 300, 3)\n",
      "변환 전 사이즈: (442, 420, 3)\n",
      "변환 전 사이즈: (245, 394, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (112, 149, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (325, 425, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (487, 377, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (400, 500, 3)\n",
      "변환 전 사이즈: (369, 500, 3)\n",
      "변환 전 사이즈: (254, 333, 3)\n",
      "변환 전 사이즈: (400, 402, 3)\n",
      "변환 전 사이즈: (237, 250, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (357, 271, 3)\n",
      "변환 전 사이즈: (500, 426, 3)\n",
      "변환 전 사이즈: (323, 431, 3)\n",
      "변환 전 사이즈: (389, 400, 3)\n",
      "변환 전 사이즈: (325, 400, 3)\n",
      "변환 전 사이즈: (329, 500, 3)\n",
      "변환 전 사이즈: (415, 500, 3)\n",
      "변환 전 사이즈: (500, 264, 3)\n",
      "변환 전 사이즈: (352, 300, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 400, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (359, 479, 3)\n",
      "변환 전 사이즈: (500, 465, 3)\n",
      "변환 전 사이즈: (330, 290, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (363, 432, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (465, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (398, 500, 3)\n",
      "변환 전 사이즈: (475, 500, 3)\n",
      "변환 전 사이즈: (399, 427, 3)\n",
      "변환 전 사이즈: (318, 424, 3)\n",
      "변환 전 사이즈: (320, 400, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (377, 500, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (179, 275, 3)\n",
      "변환 전 사이즈: (400, 316, 3)\n",
      "변환 전 사이즈: (275, 275, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 374, 3)\n",
      "변환 전 사이즈: (329, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (259, 500, 3)\n",
      "변환 전 사이즈: (249, 333, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (253, 257, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (397, 500, 3)\n",
      "변환 전 사이즈: (334, 300, 3)\n",
      "변환 전 사이즈: (439, 408, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 408, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (448, 492, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (434, 500, 3)\n",
      "변환 전 사이즈: (386, 377, 3)\n",
      "변환 전 사이즈: (391, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (336, 288, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (334, 500, 3)\n",
      "변환 전 사이즈: (262, 500, 3)\n",
      "변환 전 사이즈: (128, 192, 3)\n",
      "변환 전 사이즈: (406, 364, 3)\n",
      "Loss [1, 10](epoch, minibatch):  0.03583572387695313\n",
      "변환 전 사이즈: (457, 500, 3)\n",
      "변환 전 사이즈: (500, 400, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (252, 324, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (200, 300, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (432, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (281, 500, 3)\n",
      "변환 전 사이즈: (500, 315, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (342, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (221, 239, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (270, 326, 3)\n",
      "변환 전 사이즈: (416, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (199, 200, 3)\n",
      "변환 전 사이즈: (238, 350, 3)\n",
      "변환 전 사이즈: (348, 500, 3)\n",
      "변환 전 사이즈: (180, 240, 3)\n",
      "변환 전 사이즈: (250, 250, 3)\n",
      "변환 전 사이즈: (232, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (319, 350, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (415, 450, 3)\n",
      "변환 전 사이즈: (411, 500, 3)\n",
      "변환 전 사이즈: (500, 269, 3)\n",
      "변환 전 사이즈: (321, 219, 3)\n",
      "변환 전 사이즈: (275, 376, 3)\n",
      "변환 전 사이즈: (315, 350, 3)\n",
      "변환 전 사이즈: (200, 300, 3)\n",
      "변환 전 사이즈: (500, 450, 3)\n",
      "변환 전 사이즈: (321, 480, 3)\n",
      "변환 전 사이즈: (476, 425, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (310, 432, 3)\n",
      "변환 전 사이즈: (288, 195, 3)\n",
      "변환 전 사이즈: (296, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (230, 193, 3)\n",
      "변환 전 사이즈: (296, 257, 3)\n",
      "변환 전 사이즈: (273, 300, 3)\n",
      "변환 전 사이즈: (500, 321, 3)\n",
      "변환 전 사이즈: (306, 288, 3)\n",
      "변환 전 사이즈: (213, 422, 3)\n",
      "변환 전 사이즈: (432, 322, 3)\n",
      "변환 전 사이즈: (500, 340, 3)\n",
      "변환 전 사이즈: (190, 156, 3)\n",
      "변환 전 사이즈: (453, 397, 3)\n",
      "변환 전 사이즈: (379, 301, 3)\n",
      "변환 전 사이즈: (500, 370, 3)\n",
      "변환 전 사이즈: (323, 232, 3)\n",
      "변환 전 사이즈: (500, 412, 3)\n",
      "변환 전 사이즈: (500, 470, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (320, 240, 3)\n",
      "변환 전 사이즈: (370, 500, 3)\n",
      "변환 전 사이즈: (310, 260, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (262, 489, 3)\n",
      "변환 전 사이즈: (163, 144, 3)\n",
      "변환 전 사이즈: (347, 480, 3)\n",
      "변환 전 사이즈: (250, 239, 3)\n",
      "변환 전 사이즈: (187, 280, 3)\n",
      "변환 전 사이즈: (400, 250, 3)\n",
      "변환 전 사이즈: (186, 139, 3)\n",
      "변환 전 사이즈: (200, 151, 3)\n",
      "변환 전 사이즈: (243, 300, 3)\n",
      "변환 전 사이즈: (500, 429, 3)\n",
      "변환 전 사이즈: (377, 500, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (440, 500, 3)\n",
      "변환 전 사이즈: (150, 184, 3)\n",
      "변환 전 사이즈: (119, 150, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (484, 432, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (200, 178, 3)\n",
      "변환 전 사이즈: (461, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (300, 247, 3)\n",
      "변환 전 사이즈: (329, 425, 3)\n",
      "변환 전 사이즈: (406, 500, 3)\n",
      "변환 전 사이즈: (500, 438, 3)\n",
      "변환 전 사이즈: (460, 500, 3)\n",
      "변환 전 사이즈: (147, 156, 3)\n",
      "변환 전 사이즈: (173, 249, 3)\n",
      "변환 전 사이즈: (500, 417, 3)\n",
      "변환 전 사이즈: (247, 200, 3)\n",
      "변환 전 사이즈: (271, 376, 3)\n",
      "변환 전 사이즈: (270, 338, 3)\n",
      "변환 전 사이즈: (437, 500, 3)\n",
      "변환 전 사이즈: (381, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 323, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (352, 334, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (336, 250, 3)\n",
      "변환 전 사이즈: (500, 500, 3)\n",
      "변환 전 사이즈: (225, 254, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (200, 201, 3)\n",
      "변환 전 사이즈: (400, 500, 3)\n",
      "변환 전 사이즈: (250, 390, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (427, 400, 3)\n",
      "변환 전 사이즈: (154, 180, 3)\n",
      "변환 전 사이즈: (248, 250, 3)\n",
      "변환 전 사이즈: (264, 500, 3)\n",
      "변환 전 사이즈: (500, 370, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (245, 153, 3)\n",
      "변환 전 사이즈: (500, 391, 3)\n",
      "변환 전 사이즈: (397, 500, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (418, 500, 3)\n",
      "변환 전 사이즈: (500, 449, 3)\n",
      "변환 전 사이즈: (196, 300, 3)\n",
      "변환 전 사이즈: (312, 350, 3)\n",
      "변환 전 사이즈: (376, 379, 3)\n",
      "변환 전 사이즈: (500, 335, 3)\n",
      "변환 전 사이즈: (336, 424, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (230, 163, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (440, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (386, 356, 3)\n",
      "변환 전 사이즈: (481, 500, 3)\n",
      "변환 전 사이즈: (500, 400, 3)\n",
      "변환 전 사이즈: (366, 300, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (135, 125, 3)\n",
      "변환 전 사이즈: (200, 200, 3)\n",
      "변환 전 사이즈: (225, 198, 3)\n",
      "변환 전 사이즈: (500, 366, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (306, 277, 3)\n",
      "변환 전 사이즈: (469, 500, 3)\n",
      "변환 전 사이즈: (240, 240, 3)\n",
      "변환 전 사이즈: (300, 400, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (270, 320, 3)\n",
      "변환 전 사이즈: (331, 500, 3)\n",
      "변환 전 사이즈: (332, 360, 3)\n",
      "변환 전 사이즈: (500, 336, 3)\n",
      "변환 전 사이즈: (435, 360, 3)\n",
      "변환 전 사이즈: (269, 299, 3)\n",
      "Loss [1, 15](epoch, minibatch):  0.03524860560894012\n",
      "변환 전 사이즈: (348, 500, 3)\n",
      "변환 전 사이즈: (288, 252, 3)\n",
      "변환 전 사이즈: (500, 414, 3)\n",
      "변환 전 사이즈: (500, 391, 3)\n",
      "변환 전 사이즈: (369, 400, 3)\n",
      "변환 전 사이즈: (479, 454, 3)\n",
      "변환 전 사이즈: (500, 348, 3)\n",
      "변환 전 사이즈: (100, 239, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (454, 346, 3)\n",
      "변환 전 사이즈: (271, 204, 3)\n",
      "변환 전 사이즈: (446, 492, 3)\n",
      "변환 전 사이즈: (276, 350, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (384, 346, 3)\n",
      "변환 전 사이즈: (209, 373, 3)\n",
      "변환 전 사이즈: (214, 259, 3)\n",
      "변환 전 사이즈: (290, 387, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (321, 500, 3)\n",
      "변환 전 사이즈: (480, 366, 3)\n",
      "변환 전 사이즈: (408, 484, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 388, 3)\n",
      "변환 전 사이즈: (220, 179, 3)\n",
      "변환 전 사이즈: (500, 460, 3)\n",
      "변환 전 사이즈: (360, 339, 3)\n",
      "변환 전 사이즈: (500, 487, 3)\n",
      "변환 전 사이즈: (480, 480, 3)\n",
      "변환 전 사이즈: (252, 300, 3)\n",
      "변환 전 사이즈: (500, 365, 3)\n",
      "변환 전 사이즈: (300, 400, 3)\n",
      "변환 전 사이즈: (340, 303, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (460, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (470, 500, 3)\n",
      "변환 전 사이즈: (395, 500, 3)\n",
      "변환 전 사이즈: (480, 360, 3)\n",
      "변환 전 사이즈: (500, 436, 3)\n",
      "변환 전 사이즈: (118, 200, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (336, 419, 3)\n",
      "변환 전 사이즈: (232, 250, 3)\n",
      "변환 전 사이즈: (386, 500, 3)\n",
      "변환 전 사이즈: (490, 500, 3)\n",
      "변환 전 사이즈: (334, 500, 3)\n",
      "변환 전 사이즈: (225, 300, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (233, 280, 3)\n",
      "변환 전 사이즈: (200, 156, 3)\n",
      "변환 전 사이즈: (438, 390, 3)\n",
      "변환 전 사이즈: (260, 346, 3)\n",
      "변환 전 사이즈: (387, 283, 3)\n",
      "변환 전 사이즈: (164, 176, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (500, 500, 3)\n",
      "변환 전 사이즈: (264, 220, 3)\n",
      "변환 전 사이즈: (103, 139, 3)\n",
      "변환 전 사이즈: (419, 300, 3)\n",
      "변환 전 사이즈: (500, 337, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (476, 500, 3)\n",
      "변환 전 사이즈: (96, 140, 3)\n",
      "변환 전 사이즈: (120, 160, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 333, 3)\n",
      "변환 전 사이즈: (187, 250, 3)\n",
      "변환 전 사이즈: (396, 500, 3)\n",
      "변환 전 사이즈: (276, 300, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 500, 3)\n",
      "변환 전 사이즈: (335, 300, 3)\n",
      "변환 전 사이즈: (299, 448, 3)\n",
      "변환 전 사이즈: (360, 480, 3)\n",
      "변환 전 사이즈: (200, 150, 3)\n",
      "변환 전 사이즈: (200, 175, 3)\n",
      "변환 전 사이즈: (482, 500, 3)\n",
      "변환 전 사이즈: (270, 206, 3)\n",
      "변환 전 사이즈: (480, 360, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (180, 171, 3)\n",
      "변환 전 사이즈: (198, 382, 3)\n",
      "변환 전 사이즈: (500, 487, 3)\n",
      "변환 전 사이즈: (180, 240, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (327, 316, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (226, 276, 3)\n",
      "변환 전 사이즈: (500, 388, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (398, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (336, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (358, 361, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (335, 500, 3)\n",
      "변환 전 사이즈: (250, 229, 3)\n",
      "변환 전 사이즈: (500, 457, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (500, 436, 3)\n",
      "변환 전 사이즈: (329, 448, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (338, 400, 3)\n",
      "변환 전 사이즈: (225, 257, 3)\n",
      "변환 전 사이즈: (401, 477, 3)\n",
      "변환 전 사이즈: (360, 500, 3)\n",
      "변환 전 사이즈: (397, 490, 3)\n",
      "변환 전 사이즈: (443, 400, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (262, 350, 3)\n",
      "변환 전 사이즈: (344, 500, 3)\n",
      "변환 전 사이즈: (500, 493, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (366, 500, 3)\n",
      "변환 전 사이즈: (267, 300, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (200, 152, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (267, 347, 3)\n",
      "변환 전 사이즈: (343, 301, 3)\n",
      "변환 전 사이즈: (100, 100, 3)\n",
      "변환 전 사이즈: (333, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (332, 460, 3)\n",
      "변환 전 사이즈: (401, 490, 3)\n",
      "변환 전 사이즈: (500, 423, 3)\n",
      "변환 전 사이즈: (176, 194, 3)\n",
      "변환 전 사이즈: (500, 377, 3)\n",
      "변환 전 사이즈: (288, 253, 3)\n",
      "변환 전 사이즈: (225, 300, 3)\n",
      "변환 전 사이즈: (341, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (423, 500, 3)\n",
      "변환 전 사이즈: (173, 200, 3)\n",
      "변환 전 사이즈: (293, 390, 3)\n",
      "변환 전 사이즈: (432, 402, 3)\n",
      "변환 전 사이즈: (352, 400, 3)\n",
      "변환 전 사이즈: (500, 417, 3)\n",
      "변환 전 사이즈: (500, 409, 3)\n",
      "변환 전 사이즈: (500, 496, 3)\n",
      "변환 전 사이즈: (351, 425, 3)\n",
      "변환 전 사이즈: (360, 480, 3)\n",
      "변환 전 사이즈: (500, 494, 3)\n",
      "변환 전 사이즈: (441, 425, 3)\n",
      "변환 전 사이즈: (404, 500, 3)\n",
      "변환 전 사이즈: (500, 461, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 282, 3)\n",
      "Loss [1, 20](epoch, minibatch):  0.03492110252380371\n",
      "변환 전 사이즈: (373, 478, 3)\n",
      "변환 전 사이즈: (500, 428, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (457, 367, 3)\n",
      "변환 전 사이즈: (454, 500, 3)\n",
      "변환 전 사이즈: (322, 350, 3)\n",
      "변환 전 사이즈: (500, 346, 3)\n",
      "변환 전 사이즈: (215, 153, 3)\n",
      "변환 전 사이즈: (250, 199, 3)\n",
      "변환 전 사이즈: (400, 363, 3)\n",
      "변환 전 사이즈: (320, 240, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (288, 290, 3)\n",
      "변환 전 사이즈: (235, 200, 3)\n",
      "변환 전 사이즈: (389, 428, 3)\n",
      "변환 전 사이즈: (500, 465, 3)\n",
      "변환 전 사이즈: (322, 285, 3)\n",
      "변환 전 사이즈: (262, 350, 3)\n",
      "변환 전 사이즈: (232, 138, 3)\n",
      "변환 전 사이즈: (500, 418, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (500, 460, 3)\n",
      "변환 전 사이즈: (352, 300, 3)\n",
      "변환 전 사이즈: (343, 350, 3)\n",
      "변환 전 사이즈: (500, 277, 3)\n",
      "변환 전 사이즈: (323, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (272, 500, 3)\n",
      "변환 전 사이즈: (500, 500, 3)\n",
      "변환 전 사이즈: (497, 500, 3)\n",
      "변환 전 사이즈: (378, 450, 3)\n",
      "변환 전 사이즈: (232, 166, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (349, 500, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (402, 500, 3)\n",
      "변환 전 사이즈: (471, 500, 3)\n",
      "변환 전 사이즈: (237, 320, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (240, 320, 3)\n",
      "변환 전 사이즈: (261, 350, 3)\n",
      "변환 전 사이즈: (121, 217, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (296, 448, 3)\n",
      "변환 전 사이즈: (500, 444, 3)\n",
      "변환 전 사이즈: (337, 450, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (319, 320, 3)\n",
      "변환 전 사이즈: (449, 358, 3)\n",
      "변환 전 사이즈: (444, 500, 3)\n",
      "변환 전 사이즈: (242, 350, 3)\n",
      "변환 전 사이즈: (448, 500, 3)\n",
      "변환 전 사이즈: (411, 500, 3)\n",
      "변환 전 사이즈: (487, 331, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (497, 500, 3)\n",
      "변환 전 사이즈: (449, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (315, 448, 3)\n",
      "변환 전 사이즈: (268, 360, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (336, 448, 3)\n",
      "변환 전 사이즈: (180, 200, 3)\n",
      "변환 전 사이즈: (492, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (500, 229, 3)\n",
      "변환 전 사이즈: (480, 380, 3)\n",
      "변환 전 사이즈: (500, 489, 3)\n",
      "변환 전 사이즈: (336, 433, 3)\n",
      "변환 전 사이즈: (299, 300, 3)\n",
      "변환 전 사이즈: (500, 447, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (252, 220, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (90, 120, 3)\n",
      "변환 전 사이즈: (400, 339, 3)\n",
      "변환 전 사이즈: (225, 300, 3)\n",
      "변환 전 사이즈: (387, 367, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (389, 500, 3)\n",
      "변환 전 사이즈: (397, 500, 3)\n",
      "변환 전 사이즈: (135, 180, 3)\n",
      "변환 전 사이즈: (262, 350, 3)\n",
      "변환 전 사이즈: (198, 185, 3)\n",
      "변환 전 사이즈: (466, 500, 3)\n",
      "변환 전 사이즈: (285, 500, 3)\n",
      "변환 전 사이즈: (241, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (321, 500, 3)\n",
      "변환 전 사이즈: (500, 286, 3)\n",
      "변환 전 사이즈: (423, 478, 3)\n",
      "변환 전 사이즈: (332, 500, 3)\n",
      "변환 전 사이즈: (382, 207, 3)\n",
      "변환 전 사이즈: (328, 500, 3)\n",
      "변환 전 사이즈: (213, 200, 3)\n",
      "변환 전 사이즈: (177, 267, 3)\n",
      "변환 전 사이즈: (181, 300, 3)\n",
      "변환 전 사이즈: (222, 214, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (324, 432, 3)\n",
      "변환 전 사이즈: (275, 275, 3)\n",
      "변환 전 사이즈: (400, 361, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (299, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (315, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (320, 240, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (294, 248, 3)\n",
      "변환 전 사이즈: (500, 375, 3)\n",
      "변환 전 사이즈: (448, 282, 3)\n",
      "변환 전 사이즈: (417, 450, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (120, 90, 3)\n",
      "변환 전 사이즈: (500, 430, 3)\n",
      "변환 전 사이즈: (378, 413, 3)\n",
      "변환 전 사이즈: (454, 440, 3)\n",
      "변환 전 사이즈: (285, 380, 3)\n",
      "변환 전 사이즈: (500, 336, 3)\n",
      "변환 전 사이즈: (134, 128, 3)\n",
      "변환 전 사이즈: (320, 480, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 443, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (500, 353, 3)\n",
      "변환 전 사이즈: (350, 350, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (270, 360, 3)\n",
      "변환 전 사이즈: (500, 291, 3)\n",
      "변환 전 사이즈: (374, 500, 3)\n",
      "변환 전 사이즈: (375, 375, 3)\n",
      "변환 전 사이즈: (174, 250, 3)\n",
      "변환 전 사이즈: (301, 460, 3)\n",
      "변환 전 사이즈: (390, 500, 3)\n",
      "변환 전 사이즈: (187, 250, 3)\n",
      "변환 전 사이즈: (192, 389, 3)\n",
      "변환 전 사이즈: (320, 289, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (286, 434, 3)\n",
      "변환 전 사이즈: (414, 432, 3)\n",
      "변환 전 사이즈: (219, 500, 3)\n",
      "변환 전 사이즈: (480, 388, 3)\n",
      "변환 전 사이즈: (331, 500, 3)\n",
      "변환 전 사이즈: (326, 500, 3)\n",
      "변환 전 사이즈: (375, 500, 3)\n",
      "변환 전 사이즈: (191, 240, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\work\\python\\python_study_ai\\resnet_implement.ipynb 셀 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/work/python/python_study_ai/resnet_implement.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/work/python/python_study_ai/resnet_implement.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# loss.backward()로 gradient를 계산하고\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/work/python/python_study_ai/resnet_implement.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# optimizer를 사용하여 반영한다.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/work/python/python_study_ai/resnet_implement.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/work/python/python_study_ai/resnet_implement.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/work/python/python_study_ai/resnet_implement.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m running_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dogs 11285, 8730, 11675 3588, 5604(not dog), 11853, 2877, 6318, 9078(channel 4) /3588와 5604가 중복해서 나옴. 특정 데이터 문제일 가능성이 높아짐\n",
    "# cats 8470, 5686, 9778, 2877, 7276, 11935, 5370\n",
    "EPOCHS=30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses=[]\n",
    "    # running loss 해당 단계에서의 loss 누적값\n",
    "    running_loss=0\n",
    "\n",
    "    for i, inp in enumerate(cnd_dataloader):\n",
    "\n",
    "        inputs, labels= inp\n",
    "        # 모든 gradient를 0으로 설정, 이렇게 하지 않으면 이전 loop의 gradient값이 그대로 남아있어 제대로 학습이 되지 않는다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # train_model을 태운 다음 loss를 계산한다.\n",
    "        outputs= train_model(inputs)\n",
    "        loss= loss_f(outputs, labels)\n",
    "        # 계산한 loss를 losses에 추가한다.\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # loss.backward()로 gradient를 계산하고\n",
    "        # optimizer를 사용하여 반영한다.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        if i%5 == 0 and i>0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss/100)\n",
    "            running_loss=0.0\n",
    "\n",
    "    avg_loss= sum(losses)/len(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
