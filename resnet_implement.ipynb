{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "REopuI_ItQ-0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import glob\n",
        "import os\n",
        "# glob 결과 숫자 오름차순으로 정리해주는 라이브러리, 기능적으로 필요하지 않았음을 깨달았으나\n",
        "# 정렬 작업이 유지보수를 가정했을 때 충분히 의미 있다고 생각해서 그냥 놔두기로 함\n",
        "import natsort\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo7Vw5litWYp",
        "outputId": "7087a21b-55c7-4dda-f836-e3e29629e96d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "h7hvx9TS_df9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Vkt78evtQ-5"
      },
      "outputs": [],
      "source": [
        "# transform을 적용한 커스텀 데이터셋\n",
        "# 무조건 torch.utils.data.Dataset을 상속받아야 한다.\n",
        "class cnd_data(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_path, train=True, transforms=None):\n",
        "\n",
        "        self.train=train\n",
        "        self.transforms=transforms\n",
        "\n",
        "        # cat, dog 경로 설정\n",
        "        # self.cat_img_path=os.path.join(file_path, 'data\\kagglecatsanddogs\\PetImages\\Cat')\n",
        "        # self.dog_img_path=os.path.join(file_path, 'data\\kagglecatsanddogs\\PetImages\\Dog')\n",
        "        self.cat_img_path=os.path.join(file_path, 'data/kagglecatsanddogs/PetImages/Cat')\n",
        "        self.dog_img_path=os.path.join(file_path, 'data/kagglecatsanddogs/PetImages/Dog')\n",
        "\n",
        "        # cat, dog 이미지 목록 불러오기\n",
        "        self.cat_list=natsort.natsorted(glob.glob(self.cat_img_path + '/*.jpg'))\n",
        "        self.dog_list=natsort.natsorted(glob.glob(self.dog_img_path + '/*.jpg'))\n",
        "\n",
        "        # cat, dog 이미지 list 및 label 지정하기, 0은 cat이고, 1은 dog이다\n",
        "        # cat, dog 각각 12500개의 이미지가 존재하며, 각각 12000개는 train, 500개는 test에 사용된다\n",
        "        if self.train==True:\n",
        "            self.imgn_list=self.cat_list[:12000]+self.dog_list[:12000]\n",
        "            self.img_label=[0]*12000+[1]*12000\n",
        "\n",
        "        else:\n",
        "            self.imgn_list=self.cat_list[12000:]+self.dog_list[12000:]\n",
        "            self.img_label=[0]*500+[1]*500\n",
        "\n",
        "        # 한번에 모든 이미지를 메모리에 올리고 싶었지만 공간 부족으로 불가\n",
        "        # getitem쪽에 올렸다.\n",
        "\n",
        "\n",
        "    # __len__()은 데이터쌍의 개수를 의미한다.\n",
        "    # 아마 __len__의 크기를 기준으로 Dataloader에서 batch 묶음의 수를 결정하고\n",
        "    # __len__만큼의 데이터쌍을 가져오는 것 같다.\n",
        "    def __len__(self):\n",
        "        return len(self.img_label)\n",
        "\n",
        "    # __getitem__()은 하나의 데이터쌍(보통 데이터, 레이블)을 가져오는데 사용된다.\n",
        "    # __getitem__출력시 한 쌍의 데이터가 아니라 한 batch만큼을 한번에 불러오는 방식으로 짜고 싶었지만\n",
        "    # (만약 그렇게 한다면 Dataloader에서 불러온 다음 중첩 for문을 사용하여 사용하게 될 것이다.)\n",
        "    # 처음으로 짜는 커스텀 데이터셋이기 때문에 한 쌍의 데이터를 가져올 때마다\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # 원 데이터는 cat과 dog 폴더로 나뉘어 있으며, 각각 0~12499까지 숫자가 파일 이름으로 사용된다.\n",
        "        # 또한, train은 0~11999, test는 12000~12499 를 파일 이름으로 사용한다.\n",
        "        # train 기준 실존하는 imgn_list의 index는 0~23999까지 사용하게 되므로,\n",
        "        # 0~11999 idx의 경우 cat폴더에서 가져와야 하며,\n",
        "        # 12000~23999 idx의 경우 dog 폴더에서 가져와야 한다.(당연히 dog폴더의 train이미지는 0~11999이므로 숫자 변환도 필요하다)\n",
        "        # 라고 처음에는 생각해 왔지만 헛생각이었다... 어차피 인덱스와 이에 해당하는 이미지 경로는 연결되어 있으니 추가적인 조치를 취하지 않고도\n",
        "        # 문제를 해결할 수 있다.\n",
        "        image_data=Image.open(self.imgn_list[idx]).convert('RGB')\n",
        "\n",
        "\n",
        "        # if len(np.array(image_data).shape)==2:\n",
        "        #     image_data=image_data.convert('RGB')\n",
        "        #     print('변환 후 사이즈:',np.array(image_data).shape)\n",
        "\n",
        "        if self.transforms:\n",
        "            sample=self.transforms(image_data)\n",
        "\n",
        "        # print('사이즈:', sample.size())\n",
        "        # 이미지에서 channel이 3이 아닌 경우\n",
        "        # if sample.size()[0] != 3:\n",
        "        #     print(self.imgn_list[idx])\n",
        "        #     print('변환 사이즈:', sample.size())\n",
        "\n",
        "            # sample=sample.expand(3, -1, -1)\n",
        "            # print(sample.size())\n",
        "\n",
        "        return sample, self.img_label[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mCFV3nEDtQ-8"
      },
      "outputs": [],
      "source": [
        "# 경로 설정, py파일로 변환시 경로는 변경되어야 한다.\n",
        "# local path\n",
        "# path=os.path.abspath('../')\n",
        "# colab path\n",
        "path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/')\n",
        "\n",
        "# Resize: 크기를 224, 224로 맞춘다\n",
        "# ToTensor: 데이터 타입을 Tensor로 만든다. Tensor의 원소는 0~1로 정해진다.(https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)\n",
        "# custom으로 transform를 작성하는 것도 가능하다.\n",
        "transforms=transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVJ1kF6GtQ--",
        "outputId": "148bb901-8113-4f82-8f53-46e5fa7e818c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/data/kagglecatsanddogs/PetImages/Dog\n"
          ]
        }
      ],
      "source": [
        "cnd_train=cnd_data(file_path=path, train=True, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gmwCzZu-tQ-_"
      },
      "outputs": [],
      "source": [
        "batch=32\n",
        "cnd_dataloader=DataLoader(cnd_train, batch_size=batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a81U4uKFtQ_A"
      },
      "outputs": [],
      "source": [
        "# resnet34나 50이나 조금씩 원문에서 주장하는 model을 수정한 듯한 흔적이 보인다.\n",
        "# 하지만 지금은 resnet 원문의 것을 구현하는 입장이기 때문에\n",
        "# 모델 참조를 하다 원문과 다른 부분이 있다면 무시하고 원문대로 한다.\n",
        "# resnet34_preset=models.resnet34()\n",
        "# summary(resnet34_preset, input_size=(3, 224, 224))\n",
        "# print(resnet34_preset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5vTLO01etQ_D"
      },
      "outputs": [],
      "source": [
        "# resnet50_preset=models.resnet50()\n",
        "# summary(resnet50_preset, input_size=(3, 224, 224))\n",
        "# print(resnet50_preset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g6JnKJcZtQ_E"
      },
      "outputs": [],
      "source": [
        "# 모델을 정의할 때는 무조건 torch.nn.Module을 상속받아야 한다.\n",
        "# block은 short connection이 있는 최소 단위이며\n",
        "# group은 동일한 block 형성 패턴(논문 table 1의 conv2_x, conv3_x)을 의미한다.\n",
        "class ResNet_compat(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape=(3, 224, 224),\n",
        "                 blocks_in_model=[3, 4, 6, 3],\n",
        "                 layers_in_block=[2, 2, 2, 2],\n",
        "                 kernel_sizes=[(3,3), (3,3), (3,3), (3,3)],\n",
        "                 channel_sizes=[(64,64), (128,128), (256,256), (512,512)],\n",
        "                 class_size=2,\n",
        "                 is_plain=False):\n",
        "\n",
        "        super(ResNet_compat, self).__init__()\n",
        "\n",
        "        self.input_shape=input_shape\n",
        "        self.blocks_in_model=blocks_in_model\n",
        "        self.layers_in_block=layers_in_block\n",
        "        self.kernel_sizes=kernel_sizes\n",
        "        self.channel_sizes=channel_sizes\n",
        "        self.class_size=class_size\n",
        "        self.is_plain=is_plain\n",
        "\n",
        "\n",
        "        # pytorch에도 padding='same'이라는 옵션은 존재하지만, stride=1일\n",
        "        # 경우만 사용 가능하다.\n",
        "        # 아래 코드는 (W-F+2P)/S + 1 공식 적용한 코드로\n",
        "        # 계산 결과가 소수점이 나오지만, pytorch에서 사용하는 resnet이 이렇게 설정하였기 때문에\n",
        "        # 똑같이 진행한다.\n",
        "\n",
        "        # conv1+conv2 maxpooling\n",
        "        self.conv1=nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
        "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(), # 왜 그런지 모르겠지만 preset에는 inplace=True(default: False)\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        # conv2(maxpooling은 제외), short connection은 구현부에서 구현\n",
        "\n",
        "        self.block_forms=nn.Sequential()\n",
        "        for i in range(len(blocks_in_model)):\n",
        "            for j in range(blocks_in_model[i]):\n",
        "\n",
        "                # i는 group, j는 block\n",
        "                if i==0 and j==0:\n",
        "                    inp_channel=64\n",
        "                elif i!=0 and j==0:\n",
        "                    inp_channel=channel_sizes[i-1][-1]\n",
        "                else:\n",
        "                    inp_channel=False\n",
        "\n",
        "                # # input_channel은 block의 맨 처음+group(group: block묶음)의 맨 처음인 경우만 사용됨\n",
        "                # self.block_forms.add_module(nn.Sequential(*self.build_block(\n",
        "                #     self.layers_in_block[i],\n",
        "                #     kernel_sizes=self.kernel_sizes[i],\n",
        "                #     channel_sizes=self.channel_sizes[i],\n",
        "                #     input_channel=inp_channel,\n",
        "                #     is_plain=False\n",
        "                # )))\n",
        "                # input_channel은 block의 맨 처음+group(group: block묶음)의 맨 처음인 경우만 사용됨\n",
        "                self.block_forms.add_module(f'bblock{i, j}',self.build_block(\n",
        "                    self.layers_in_block[i],\n",
        "                    kernel_sizes=self.kernel_sizes[i],\n",
        "                    channel_sizes=self.channel_sizes[i],\n",
        "                    input_channel=inp_channel,\n",
        "                    is_plain=False\n",
        "                ))\n",
        "\n",
        "\n",
        "\n",
        "        # summary가 안 먹혀서 새로 짠 코드\n",
        "        # self.model_body=nn.Sequential(*self.block_forms)\n",
        "\n",
        "        # 선언을 하려고 하면 추가 입력이 필요해서 forward에 설정해야 하는 상황...\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.end_avg2d=nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.end_linear=nn.Linear(in_features=self.channel_sizes[-1][-1], out_features=2, bias=True)\n",
        "        self.end_softmax=nn.Softmax(-1)\n",
        "\n",
        "    # input_channel은 block의 맨 처음+group(group: block묶음)의 맨 처음인 경우만 사용됨\n",
        "    def build_block(self, layers, kernel_sizes, channel_sizes, input_channel, is_plain=False):\n",
        "\n",
        "        full_block=nn.Sequential()\n",
        "        for i in range(layers):\n",
        "            if kernel_sizes[i]!= 1:\n",
        "                layer_padding=(1,1)\n",
        "            else:\n",
        "                layer_padding=(0,0)\n",
        "\n",
        "            if input_channel and i==0:\n",
        "                if input_channel != channel_sizes[i]:\n",
        "                    f_stride=2\n",
        "                else:\n",
        "                    f_stride=1\n",
        "                full_block.add_module(f'conv{i}',nn.Conv2d(in_channels=input_channel,\n",
        "                                            out_channels=channel_sizes[i],\n",
        "                                            kernel_size=kernel_sizes[i],\n",
        "                                            padding=layer_padding,\n",
        "                                            stride=f_stride,\n",
        "                                            bias=False\n",
        "                                            ))\n",
        "            else:\n",
        "                # 50이상은 channel이 일시적으로 늘어나도 feature map의 크기가 그대로임음 명심할 것\n",
        "                # padding만 어떻게 할지 고민해보자... kernel_size가 1일 때는 패딩 제외?? 아니면 3일 때만 padding 1??\n",
        "                full_block.add_module(f'conv{i}',nn.Conv2d(in_channels=channel_sizes[i-1],\n",
        "                                            out_channels=channel_sizes[i],\n",
        "                                            kernel_size=kernel_sizes[i],\n",
        "                                            padding=layer_padding,\n",
        "                                            bias=False\n",
        "                                            ))\n",
        "            # batch_normalization\n",
        "            full_block.add_module(f'batnorm{i}',nn.BatchNorm2d(channel_sizes[i], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
        "\n",
        "            # short connection은 구현부에서 만들기 때문에 block의 마지막 layer가 아니라면 relu 추가\n",
        "            # inplace 옵션이 있고, pre-model에서는 사용하긴 사용하지만 왜 사용하는지 모르겠어서 사용 안함\n",
        "            if i< layers-1:\n",
        "                full_block.add_module(f'relu{i}',nn.ReLU())\n",
        "\n",
        "        return full_block\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x=self.conv1(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        # model body\n",
        "        for block in self.block_forms:\n",
        "            block= block # 만약 구조적 문제가 해결되면 삭제 시도해볼 것\n",
        "            identity=x\n",
        "            x=block(x)\n",
        "\n",
        "            if block[0].in_channels != block[0].out_channels:\n",
        "                self.reduce=nn.Conv2d(\n",
        "                    block[0].in_channels,\n",
        "                    block[0].out_channels,\n",
        "                    kernel_size=(1,1),\n",
        "                    stride=2).to(device)\n",
        "                identity=self.reduce(identity)\n",
        "\n",
        "            x+=identity\n",
        "            x=self.relu(x)\n",
        "\n",
        "\n",
        "        # 끝단\n",
        "        x=self.end_avg2d(x)\n",
        "        x=torch.flatten(x, 1, -1)\n",
        "\n",
        "        # x현재 shape는 [2, 512, 1, 1]\n",
        "        x=self.end_linear(x)\n",
        "        x=self.end_softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "        # return self.conv_temp(x)\n",
        "\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN4V5FULtQ_F",
        "outputId": "1915f31e-35ba-407e-dc09-56c0dc0f6116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
            "             ReLU-13           [-1, 64, 56, 56]               0\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "             ReLU-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
            "             ReLU-25          [-1, 128, 28, 28]               0\n",
            "           Conv2d-26          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
            "             ReLU-28          [-1, 128, 28, 28]               0\n",
            "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
            "             ReLU-31          [-1, 128, 28, 28]               0\n",
            "           Conv2d-32          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
            "             ReLU-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
            "             ReLU-37          [-1, 128, 28, 28]               0\n",
            "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
            "             ReLU-40          [-1, 128, 28, 28]               0\n",
            "           Conv2d-41          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
            "             ReLU-43          [-1, 128, 28, 28]               0\n",
            "           Conv2d-44          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
            "             ReLU-46          [-1, 128, 28, 28]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "           Conv2d-50          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-51          [-1, 256, 14, 14]             512\n",
            "             ReLU-52          [-1, 256, 14, 14]               0\n",
            "           Conv2d-53          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-54          [-1, 256, 14, 14]             512\n",
            "             ReLU-55          [-1, 256, 14, 14]               0\n",
            "           Conv2d-56          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
            "             ReLU-58          [-1, 256, 14, 14]               0\n",
            "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
            "             ReLU-61          [-1, 256, 14, 14]               0\n",
            "           Conv2d-62          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-63          [-1, 256, 14, 14]             512\n",
            "             ReLU-64          [-1, 256, 14, 14]               0\n",
            "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
            "             ReLU-67          [-1, 256, 14, 14]               0\n",
            "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
            "             ReLU-70          [-1, 256, 14, 14]               0\n",
            "           Conv2d-71          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-72          [-1, 256, 14, 14]             512\n",
            "             ReLU-73          [-1, 256, 14, 14]               0\n",
            "           Conv2d-74          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
            "             ReLU-76          [-1, 256, 14, 14]               0\n",
            "           Conv2d-77          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-78          [-1, 256, 14, 14]             512\n",
            "             ReLU-79          [-1, 256, 14, 14]               0\n",
            "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
            "             ReLU-82          [-1, 256, 14, 14]               0\n",
            "           Conv2d-83            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-84            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-85            [-1, 512, 7, 7]               0\n",
            "           Conv2d-86            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-87            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-88            [-1, 512, 7, 7]               0\n",
            "           Conv2d-89            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-90            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-91            [-1, 512, 7, 7]               0\n",
            "           Conv2d-92            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-93            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-94            [-1, 512, 7, 7]               0\n",
            "           Conv2d-95            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-96            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-97            [-1, 512, 7, 7]               0\n",
            "           Conv2d-98            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-99            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-100            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-101            [-1, 512, 1, 1]               0\n",
            "          Linear-102                    [-1, 2]           1,026\n",
            "         Softmax-103                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 21,111,874\n",
            "Trainable params: 21,111,874\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 83.07\n",
            "Params size (MB): 80.54\n",
            "Estimated Total Size (MB): 164.18\n",
            "----------------------------------------------------------------\n",
            "ResNet_compat(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block_forms): Sequential(\n",
            "    (bblock(0, 0)): Sequential(\n",
            "      (conv0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(0, 1)): Sequential(\n",
            "      (conv0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(0, 2)): Sequential(\n",
            "      (conv0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(1, 0)): Sequential(\n",
            "      (conv0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(1, 1)): Sequential(\n",
            "      (conv0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(1, 2)): Sequential(\n",
            "      (conv0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(1, 3)): Sequential(\n",
            "      (conv0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(2, 0)): Sequential(\n",
            "      (conv0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(2, 1)): Sequential(\n",
            "      (conv0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(2, 2)): Sequential(\n",
            "      (conv0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(2, 3)): Sequential(\n",
            "      (conv0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(2, 4)): Sequential(\n",
            "      (conv0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(2, 5)): Sequential(\n",
            "      (conv0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(3, 0)): Sequential(\n",
            "      (conv0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(3, 1)): Sequential(\n",
            "      (conv0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (bblock(3, 2)): Sequential(\n",
            "      (conv0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU()\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (batnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (end_avg2d): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (end_linear): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (end_softmax): Softmax(dim=-1)\n",
            "  (reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "train_model=ResNet_compat().to(device)\n",
        "summary(train_model, input_size=(3, 224, 224))\n",
        "print(train_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bG9T-X7FtQ_G"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.01\n",
        "\n",
        "loss_f= nn.CrossEntropyLoss()\n",
        "# train_model.parameters: 최적화할 대상의 파라미터\n",
        "# lr=learning_rate\n",
        "optimizer = torch.optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "writer=SummaryWriter('./resnet_log')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_save_path='./resnet_weight'"
      ],
      "metadata": {
        "id": "VeNyDZV-sA9D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_list=natsort.natsorted(glob.glob('./resnet_weight''/*.pth'), reverse=True)\n",
        "\n",
        "if weight_list:\n",
        "  start_epoch=weight_list[0].split('_')[-1].split('.')[0]\n",
        "  print(f'{start_epoch} epoch 부터 시작합니다.')\n",
        "else:\n",
        "  start_epoch=0\n",
        "  print('처음부터 시작합니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yX1QWtHsu0_",
        "outputId": "999cd433-43c5-4e74-f2cb-d0db28ce7b2a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "처음부터 시작합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWooXKQWtQ_H"
      },
      "outputs": [],
      "source": [
        "# dogs 11285, 8730, 11675 3588, 5604(not dog), 11853, 2877, 6318, 9078(channel 4), 11410 /3588와 5604가 중복해서 나옴. 특정 데이터 문제일 가능성이 높아짐\n",
        "# cats 8470, 5686, 9778, 2877, 7276, 11935, 5370\n",
        "# 위 문제는 비트 수준(bit-depth)문제로 발생한 것이며, 이미 해결함\n",
        "\n",
        "EPOCHS=30\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    losses=[]\n",
        "    # running loss: 5batch동안 loss 누적값\n",
        "    running_loss=0\n",
        "    running_acc=0\n",
        "\n",
        "    # epoch_total_loss: 1 epoch에서 발생한 loss 누적값, 750(1 epoch batch수)을 나눠서 평균 loss값을 구하는데 사용할 예정\n",
        "    epoch_total_loss=0\n",
        "    epoch_total_acc=0\n",
        "    start_time=time.time()\n",
        "\n",
        "\n",
        "    for i, inp in enumerate(cnd_dataloader):\n",
        "\n",
        "        input, label= inp\n",
        "        input, label= input.to(device), torch.Tensor(label).to(device)\n",
        "        # 모든 gradient를 0으로 설정, 이렇게 하지 않으면 이전 loop의 gradient값이 그대로 남아있어 제대로 학습이 되지 않는다.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # train_model을 태운 다음 loss를 계산한다.\n",
        "        output= train_model(input)\n",
        "        loss= loss_f(output, label)\n",
        "\n",
        "        # accuracy를 계산한다.\n",
        "        correct=0\n",
        "        for t in zip(output.tolist(), label.tolist()):\n",
        "          if t[0][0] >= 0.5:\n",
        "              ans=0\n",
        "          else:\n",
        "              ans=1\n",
        "          if ans==t[1]:\n",
        "            correct+=1\n",
        "          else:\n",
        "            pass\n",
        "        print(f'이번 batch에서는 {correct}개 맞았습니다.')\n",
        "\n",
        "        # 계산한 loss를 losses에 추가한다.\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # loss.backward()로 gradient를 계산하고\n",
        "        # optimizer를 사용하여 반영한다.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss+=loss.item()\n",
        "        running_acc+=correct\n",
        "\n",
        "        if i%5 == 0 and i>0:\n",
        "            end_time=time.time()\n",
        "\n",
        "            print(running_acc)\n",
        "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss/100)\n",
        "            print(f'Accuracy [{epoch+1}, {i}](epoch, minibatch): ', running_acc/(batch*5))\n",
        "            print('time taken:', end_time-start_time)\n",
        "            start_time=end_time\n",
        "            epoch_total_loss+=running_loss\n",
        "            epoch_total_acc+=running_acc\n",
        "            running_loss=0.0\n",
        "            running_acc=0\n",
        "\n",
        "    torch.save(train_model.state_dict(), f'model_weights_{epoch}.pth')\n",
        "    writer.add_scalar(\"Loss / epoch \", epoch_total_loss/len(cnd_train), epoch)\n",
        "    writer.add_scalar(\"Accuracy / epoch\", epoch_total_acc/len(cnd_train), epoch)\n",
        "\n",
        "\n",
        "    # avg_loss= sum(losses)/len(losses)\n",
        "\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard test\n",
        "writer=SummaryWriter()\n",
        "writer.add_scalar(\"Loss / epoch \", epoch_total_loss/len(cnd_train), i)"
      ],
      "metadata": {
        "id": "m3DK2cmiFDES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4EYgxyItQ_J"
      },
      "outputs": [],
      "source": [
        "# no gpu\n",
        "# Loss [1, 5](epoch, minibatch):  0.04158005654811859\n",
        "# time taken: 184.4762670993805\n",
        "# Loss [1, 10](epoch, minibatch):  0.034206237196922305\n",
        "# time taken: 139.53229141235352\n",
        "# Loss [1, 15](epoch, minibatch):  0.03538666427135467\n",
        "# time taken: 144.29514956474304\n",
        "# Loss [1, 20](epoch, minibatch):  0.03478239357471466\n",
        "# time taken: 142.34847784042358\n",
        "# Loss [1, 25](epoch, minibatch):  0.0355976140499115\n",
        "# time taken: 146.32465648651123\n",
        "# Loss [1, 30](epoch, minibatch):  0.03640728116035461\n",
        "# time taken: 143.51593947410583\n",
        "# Loss [1, 35](epoch, minibatch):  0.034946812391281126\n",
        "# time taken: 145.67319536209106\n",
        "# Loss [1, 40](epoch, minibatch):  0.034260995388031006\n",
        "# time taken: 146.46410942077637\n",
        "# Loss [1, 45](epoch, minibatch):  0.035030335783958436\n",
        "# time taken: 148.0001323223114\n",
        "# Loss [1, 50](epoch, minibatch):  0.034637700319290164\n",
        "# time taken: 140.45694208145142"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu\n",
        "# Loss [1, 5](epoch, minibatch):  0.04298167526721954\n",
        "# time taken: 99.36302304267883\n",
        "# Loss [1, 10](epoch, minibatch):  0.03436670839786529\n",
        "# time taken: 74.46278643608093\n",
        "# Loss [1, 15](epoch, minibatch):  0.034922510385513306\n",
        "# time taken: 76.45175623893738\n",
        "# Loss [1, 20](epoch, minibatch):  0.03464948296546936\n",
        "# time taken: 74.64323735237122\n",
        "# Loss [1, 25](epoch, minibatch):  0.03538934946060181\n",
        "# time taken: 75.90337038040161"
      ],
      "metadata": {
        "id": "XsmXwSCK7uaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actual(gpu)\n",
        "# Loss [1, 5](epoch, minibatch):  0.04231234908103943\n",
        "# time taken: 149.16420197486877\n",
        "# Loss [1, 10](epoch, minibatch):  0.03472795844078064\n",
        "# time taken: 124.82707333564758\n",
        "# Loss [1, 15](epoch, minibatch):  0.03435707986354828\n",
        "# time taken: 124.88354778289795\n",
        "# Loss [1, 20](epoch, minibatch):  0.03444426357746124\n",
        "# time taken: 124.8115782737732\n",
        "# Loss [1, 25](epoch, minibatch):  0.034185900688171386\n",
        "# time taken: 126.37940764427185\n",
        "# Loss [1, 30](epoch, minibatch):  0.03381989479064942\n",
        "# time taken: 125.1712646484375\n",
        "# Loss [1, 35](epoch, minibatch):  0.03427061080932617\n",
        "# time taken: 122.49369931221008\n",
        "# Loss [1, 40](epoch, minibatch):  0.034102092981338504\n",
        "# time taken: 124.81402468681335\n",
        "# Loss [1, 45](epoch, minibatch):  0.03363831460475922\n",
        "# time taken: 122.82072591781616\n",
        "# Loss [1, 50](epoch, minibatch):  0.033385589718818665\n",
        "# time taken: 121.55848360061646"
      ],
      "metadata": {
        "id": "H9h3h39_8ENw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}