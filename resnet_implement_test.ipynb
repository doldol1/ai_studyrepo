{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-uFjHiLYBYmI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import glob\n",
        "import os\n",
        "# glob 결과 숫자 오름차순으로 정리해주는 라이브러리, 기능적으로 필요하지 않았음을 깨달았으나\n",
        "# 정렬 작업이 유지보수를 가정했을 때 충분히 의미 있다고 생각해서 그냥 놔두기로 함\n",
        "import natsort\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import drive.MyDrive.Colab_Notebooks.resnet_datanmodel as datanmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVDs_iEfChis",
        "outputId": "a4fb9f6f-d8f0-4028-e7d9-192c28848bc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "ReqZm3rGCmxq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정, py파일로 변환시 경로는 변경되어야 한다.\n",
        "# local path\n",
        "# path=os.path.abspath('../')\n",
        "# colab path\n",
        "path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/')\n",
        "\n",
        "# Resize: 크기를 224, 224로 맞춘다\n",
        "# ToTensor: 데이터 타입을 Tensor로 만든다. Tensor의 원소는 0~1로 정해진다.(https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)\n",
        "# custom으로 transform를 작성하는 것도 가능하다.\n",
        "transforms=transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "MQKHAH67CyFY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnd_test=datanmodel.cnd_data(file_path=path, train=False, transforms=transforms)"
      ],
      "metadata": {
        "id": "3WUaWbkkC2Rm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch=20\n",
        "cnd_dataloader=DataLoader(cnd_test, batch_size=batch, shuffle=True)"
      ],
      "metadata": {
        "id": "oERWG6qSDg2n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model=datanmodel.ResNet_compat().to(device)\n",
        "# summary(test_model, input_size=(3, 224, 224))\n",
        "# print(test_model)"
      ],
      "metadata": {
        "id": "hAy7xDGLEQKV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_f= nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "c4kLWYsqEQ-u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_log/')\n",
        "weight_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/')"
      ],
      "metadata": {
        "id": "bHS7RuFMEaqD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer=SummaryWriter(log_save_path)"
      ],
      "metadata": {
        "id": "q0SSDMEjEi0X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_list=natsort.natsorted(glob.glob(weight_save_path+'/*.pth'), reverse=False)"
      ],
      "metadata": {
        "id": "goWAb29sElie"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 epoch까지의 값들을 확인한다.\n",
        "START_EPOCHS=30\n",
        "EPOCHS=35\n",
        "weight_list=weight_list[START_EPOCHS:EPOCHS]"
      ],
      "metadata": {
        "id": "p2APwIylEyXk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch_path in weight_list:\n",
        "\n",
        "    print(epoch_path)\n",
        "\n",
        "    # GPU 사용 불가시\n",
        "    if device=='cpu':\n",
        "      loaded_weight=torch.load(weight_list[0], map_location=torch.device('cpu'))\n",
        "      if isinstance(test_model,nn.DataParallel):\n",
        "        print('cpu 병렬')\n",
        "      else:\n",
        "        print('cpu 병렬 x')\n",
        "\n",
        "    # GPU 사용 가능시\n",
        "    else:\n",
        "      loaded_weight=torch.load(weight_list[0])\n",
        "      if isinstance(test_model,nn.DataParallel):\n",
        "        print('gpu 병렬')\n",
        "      else:\n",
        "        print('gpu 병렬 x')\n",
        "\n",
        "    model_key=test_model.state_dict().keys()\n",
        "    weight_key=loaded_weight.keys()\n",
        "\n",
        "    diff_list=list()\n",
        "    for key in weight_key:\n",
        "      if key not in model_key:\n",
        "        diff_list.append(key)\n",
        "\n",
        "    for diff_key in diff_list:\n",
        "      del loaded_weight[diff_key]\n",
        "\n",
        "    test_model.load_state_dict(loaded_weight)\n",
        "\n",
        "    epoch=int(epoch_path.split('_')[-1].split('.')[0])\n",
        "\n",
        "\n",
        "    losses=[]\n",
        "    accs=[]\n",
        "\n",
        "    # epoch_total_loss: 1 epoch에서 발생한 loss 누적값, 750(1 epoch batch수)을 나눠서 평균 loss값을 구하는데 사용할 예정\n",
        "    epoch_total_loss=0\n",
        "    epoch_total_acc=0\n",
        "    start_time=time.time()\n",
        "\n",
        "\n",
        "    for i, inp in enumerate(cnd_dataloader):\n",
        "\n",
        "        input, label= inp\n",
        "        input, label= input.to(device), torch.Tensor(label).to(device)\n",
        "\n",
        "\n",
        "        # test_model을 태운 다음 loss를 계산한다.\n",
        "        output= test_model(input)\n",
        "        loss= loss_f(output, label)\n",
        "\n",
        "        # accuracy를 계산한다.\n",
        "        correct=0\n",
        "        for t in zip(output.tolist(), label.tolist()):\n",
        "          if t[0][0] >= 0.5:\n",
        "              ans=0\n",
        "          else:\n",
        "              ans=1\n",
        "          if ans==t[1]:\n",
        "            correct+=1\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "        # 계산한 loss를 losses에 추가한다.\n",
        "\n",
        "\n",
        "        epoch_total_loss+=loss.item()\n",
        "        epoch_total_acc+=correct\n",
        "\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    avg_loss=(epoch_total_loss/100) / len(cnd_test)\n",
        "    avg_acc=epoch_total_acc / len(cnd_test)\n",
        "\n",
        "    print(f'Loss [{epoch+1}](epoch): ', avg_loss)\n",
        "    print(f'Accuracy [{epoch+1}](epoch): ', avg_acc)\n",
        "    print('time taken(per epoch):', end_time-start_time)\n",
        "\n",
        "    losses.append(avg_loss)\n",
        "    accs.append(avg_acc)\n",
        "\n",
        "    # writer.add_scalar(\"Loss / epoch \", epoch_total_loss/len(cnd_test), epoch)\n",
        "    # writer.add_scalar(\"Accuracy / epoch\", epoch_total_acc/len(cnd_test), epoch)\n",
        "\n",
        "writer.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qQUHZSnF8fb",
        "outputId": "d660c4c9-9cee-48bf-99fd-6d807766c76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/model_weights_30.pth\n",
            "cpu 병렬 x\n",
            "Loss [31](epoch):  0.0001812850484251976\n",
            "Accuracy [31](epoch):  0.946\n",
            "time taken(per epoch): 541.6370379924774\n",
            "/content/drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/model_weights_31.pth\n",
            "cpu 병렬 x\n",
            "Loss [32](epoch):  0.00018184634417295456\n",
            "Accuracy [32](epoch):  0.948\n",
            "time taken(per epoch): 175.76138830184937\n",
            "/content/drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/model_weights_32.pth\n",
            "cpu 병렬 x\n",
            "Loss [33](epoch):  0.0001829022765159607\n",
            "Accuracy [33](epoch):  0.942\n",
            "time taken(per epoch): 174.63551259040833\n",
            "/content/drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/model_weights_33.pth\n",
            "cpu 병렬 x\n",
            "Loss [34](epoch):  0.0001810843101143837\n",
            "Accuracy [34](epoch):  0.95\n",
            "time taken(per epoch): 173.35347723960876\n",
            "/content/drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/model_weights_34.pth\n",
            "cpu 병렬 x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 폴더에 가중치가 있으면 불러온다.\n",
        "# 아래와 같이 코드가 복잡한 이유는 GPU일 때와 CPU일 때의 차이가 있기 때문에 이를 맞춰줘야 했기 때문\n",
        "# 또한 병렬 처리가 된 GPU의 경우 추가로 key를 생성하는데, 비병렬 상황에서는 이를 제거해야 된다.\n",
        "weight_list=natsort.natsorted(glob.glob(weight_save_path+'/*.pth'), reverse=True)\n",
        "\n",
        "if weight_list:\n",
        "  start_epoch=int(weight_list[0].split('_')[-1].split('.')[0])+1\n",
        "  print(f'{start_epoch+1} epoch 부터 시작합니다.')\n",
        "\n",
        "  # GPU 사용 불가시\n",
        "  if device=='cpu':\n",
        "    loaded_weight=torch.load(weight_list[0], map_location=torch.device('cpu'))\n",
        "    if isinstance(train_model,nn.DataParallel):\n",
        "      print('cpu 병렬')\n",
        "    else:\n",
        "      print('cpu 병렬 x')\n",
        "\n",
        "  # GPU 사용 가능시\n",
        "  else:\n",
        "    loaded_weight=torch.load(weight_list[0])\n",
        "    if isinstance(train_model,nn.DataParallel):\n",
        "      print('gpu 병렬')\n",
        "    else:\n",
        "      print('gpu 병렬 x')\n",
        "\n",
        "  model_key=train_model.state_dict().keys()\n",
        "  weight_key=loaded_weight.keys()\n",
        "\n",
        "  diff_list=list()\n",
        "  for key in weight_key:\n",
        "    if key not in model_key:\n",
        "      diff_list.append(key)\n",
        "\n",
        "  for diff_key in diff_list:\n",
        "    del loaded_weight[diff_key]\n",
        "\n",
        "  train_model.load_state_dict(loaded_weight)\n",
        "\n",
        "else:\n",
        "  start_epoch=0\n",
        "  print('처음부터 시작합니다.')"
      ],
      "metadata": {
        "id": "hrL_jXjCPF9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}