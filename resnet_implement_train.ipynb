{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10908,"status":"ok","timestamp":1688054779187,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"REopuI_ItQ-0"},"outputs":[],"source":["import torch\n","import glob\n","import os\n","# glob 결과 숫자 오름차순으로 정리해주는 라이브러리, 기능적으로 필요하지 않았음을 깨달았으나\n","# 정렬 작업이 유지보수를 가정했을 때 충분히 의미 있다고 생각해서 그냥 놔두기로 함\n","import natsort\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch import nn\n","from torchvision import models\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import numpy as np\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19586,"status":"ok","timestamp":1688054798756,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"Bo7Vw5litWYp","outputId":"67c2fc02-4451-4cce-a45f-c86aa11f6a1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import drive.MyDrive.Colab_Notebooks.resnet_datanmodel as datanmodel"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688054798757,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"h7hvx9TS_df9"},"outputs":[],"source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1688054798758,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"mCFV3nEDtQ-8"},"outputs":[],"source":["# 경로 설정, py파일로 변환시 경로는 변경되어야 한다.\n","# local path\n","# path=os.path.abspath('../')\n","# colab path\n","path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/')\n","\n","# Resize: 크기를 224, 224로 맞춘다\n","# ToTensor: 데이터 타입을 Tensor로 만든다. Tensor의 원소는 0~1로 정해진다.(https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)\n","# custom으로 transform를 작성하는 것도 가능하다.\n","transforms=transforms.Compose([\n","    transforms.Resize(size=(224, 224)),\n","    transforms.ToTensor()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVJ1kF6GtQ--"},"outputs":[],"source":["cnd_train=datanmodel.cnd_data(file_path=path, train=True, transforms=transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gmwCzZu-tQ-_"},"outputs":[],"source":["batch=32\n","cnd_dataloader=DataLoader(cnd_train, batch_size=batch, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uN4V5FULtQ_F"},"outputs":[],"source":["# 34 model\n","train_model=datanmodel.ResNet_compat().to(device)\n","# # 50 model\n","# train_model=datanmodel.ResNet_compat(blocks_in_model=[3, 4, 6, 3],\n","#                          layers_in_block=[3, 3, 3, 3],\n","#                          kernel_sizes=[(1,3,1), (1,3,1), (1,3,1), (1,3,1)],\n","#                          channel_sizes=[(64,64,256), (128,128,512), (256,256,1024), (512,512, 2048)]).to(device)\n","\n","\n","summary(train_model, input_size=(3, 224, 224))\n","print(train_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bG9T-X7FtQ_G"},"outputs":[],"source":["learning_rate=0.01\n","\n","loss_f= nn.CrossEntropyLoss()\n","# train_model.parameters: 최적화할 대상의 파라미터\n","optimizer = torch.optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeNyDZV-sA9D"},"outputs":[],"source":["log_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_log/')\n","weight_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAC_szF7uHgQ"},"outputs":[],"source":["writer=SummaryWriter(log_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yX1QWtHsu0_"},"outputs":[],"source":["# 폴더에 가중치가 있으면 불러온다.\n","# 아래와 같이 코드가 복잡한 이유는 GPU일 때와 CPU일 때의 차이가 있기 때문에 이를 맞춰줘야 했기 때문\n","# 또한 병렬 처리가 된 GPU의 경우 추가로 key를 생성하는데, 비병렬 상황에서는 이를 제거해야 된다.\n","weight_list=natsort.natsorted(glob.glob(weight_save_path+'/*.pth'), reverse=True)\n","\n","if weight_list:\n","  start_epoch=int(weight_list[0].split('_')[-1].split('.')[0])+1\n","  print(f'{start_epoch+1} epoch 부터 시작합니다.')\n","\n","  # GPU 사용 불가시\n","  if device=='cpu':\n","    loaded_weight=torch.load(weight_list[0], map_location=torch.device('cpu'))\n","    if isinstance(train_model,nn.DataParallel):\n","      print('cpu 병렬')\n","    else:\n","      print('cpu 병렬 x')\n","\n","  # GPU 사용 가능시\n","  else:\n","    loaded_weight=torch.load(weight_list[0])\n","    if isinstance(train_model,nn.DataParallel):\n","      print('gpu 병렬')\n","    else:\n","      print('gpu 병렬 x')\n","\n","  model_key=train_model.state_dict().keys()\n","  weight_key=loaded_weight.keys()\n","\n","  diff_list=list()\n","  for key in weight_key:\n","    if key not in model_key:\n","      diff_list.append(key)\n","\n","  for diff_key in diff_list:\n","    del loaded_weight[diff_key]\n","\n","  train_model.load_state_dict(loaded_weight)\n","\n","else:\n","  start_epoch=0\n","  print('처음부터 시작합니다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZWooXKQWtQ_H"},"outputs":[],"source":["# dogs 11285, 8730, 11675 3588, 5604(not dog), 11853, 2877, 6318, 9078(channel 4), 11410 /3588와 5604가 중복해서 나옴. 특정 데이터 문제일 가능성이 높아짐\n","# cats 8470, 5686, 9778, 2877, 7276, 11935, 5370\n","# 위 문제는 비트 수준(bit-depth)문제로 발생한 것이며, 이미 해결함\n","\n","EPOCHS=40\n","\n","for epoch in range(start_epoch, EPOCHS):\n","    # running loss: 5batch동안 loss 누적값\n","    running_loss=0\n","    running_acc=0\n","\n","    # epoch_total_loss: 1 epoch에서 발생한 loss 누적값, 750(1 epoch batch수)을 나눠서 평균 loss값을 구하는데 사용할 예정\n","    epoch_total_loss=0\n","    epoch_total_acc=0\n","    start_time=time.time()\n","\n","\n","    for i, inp in enumerate(cnd_dataloader):\n","\n","        input, label= inp\n","        input, label= input.to(device), torch.Tensor(label).to(device)\n","        # 모든 gradient를 0으로 설정, 이렇게 하지 않으면 이전 loop의 gradient값이 그대로 남아있어 제대로 학습이 되지 않는다.\n","        optimizer.zero_grad()\n","\n","        # train_model을 태운 다음 loss를 계산한다.\n","        output= train_model(input)\n","        loss= loss_f(output, label)\n","\n","        # accuracy를 계산한다.\n","        correct=0\n","        for t in zip(output.tolist(), label.tolist()):\n","          if t[0][0] >= 0.5:\n","              ans=0\n","          else:\n","              ans=1\n","          if ans==t[1]:\n","            correct+=1\n","          else:\n","            pass\n","\n","        # loss.backward()로 gradient를 계산하고\n","        # optimizer를 사용하여 반영한다.\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss+=loss.item()\n","        running_acc+=correct\n","\n","        if i%5 == 4 and i>0:\n","            end_time=time.time()\n","\n","            print(f'Loss [{epoch+1}, {i+1}](epoch, minibatch): ', running_loss/100)\n","            print(f'Accuracy [{epoch+1}, {i+1}](epoch, minibatch): ', running_acc/(batch*5))\n","            print('time taken(per 5 batch):', end_time-start_time)\n","            start_time=end_time\n","            epoch_total_loss+=running_loss\n","            epoch_total_acc+=running_acc\n","            running_loss=0.0\n","            running_acc=0\n","    # resnet 34 저장\n","    torch.save(train_model.state_dict(), os.path.join(weight_save_path, f'model_weights_{epoch}.pth'))\n","    # resnet 50 저장\n","    # torch.save(train_model.state_dict(), os.path.join(weight_save_path, f'model_50_weights_{epoch}.pth'))\n","    writer.add_scalar(\"Loss / epoch \", epoch_total_loss/len(cnd_train), epoch)\n","    writer.add_scalar(\"Accuracy / epoch\", epoch_total_acc/len(cnd_train), epoch)\n","\n","\n","writer.close()\n"]},{"cell_type":"markdown","metadata":{"id":"3e7SHuwRlMpl"},"source":["아래는 가중치 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cXKN5Oh_5wKz"},"outputs":[],"source":["raise Exception(\"에러 메시지\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"H9h3h39_8ENw"},"outputs":[],"source":["block_f=nn.Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_YhmP7Nolqnr"},"outputs":[],"source":["block_f.add_module('block1', train_model.build_block(3,\n","                                                     kernel_sizes=(1,3,1),\n","                                                     channel_sizes=(64, 64, 256),\n","                                                     input_channel=64,\n","                                                     is_plain=False))\n","\n","# block_f.add_module('block1', train_model.build_block(2,\n","#                                                      kernel_sizes=(3,3),\n","#                                                      channel_sizes=(64, 64),\n","#                                                      input_channel=64,\n","#                                                      is_plain=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VEzF3SLUmWf8"},"outputs":[],"source":["x=torch.Tensor(1, 64, 56, 56)\n","\n","for block in block_f:\n","  identity=x\n","  x=block(x)\n","\n","  if block[0].in_channels != block[-2].out_channels:\n","      reduce=nn.Conv2d(\n","          block[0].in_channels,\n","          block[-2].out_channels,\n","          kernel_size=(1,1),\n","          stride=2).to(device)\n","      identity=reduce(identity)\n","      print(identity.shape)\n","\n","  x+=identity\n","  x=self.relu(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n7pkplzDqFxF"},"outputs":[],"source":["ts=torch.Tensor(1, 64, 56, 56)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eoGj8hEhq4el"},"outputs":[],"source":["print(block_f(ts).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MEn1Egunr4ox"},"outputs":[],"source":["resnet50_preset=models.resnet50()\n","summary(resnet50_preset, input_size=(3, 224, 224))\n","print(resnet50_preset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O6rPbCvbtWK1"},"outputs":[],"source":["train_model.load_state_dict(loaded_weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DyVwivjetpLb"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}