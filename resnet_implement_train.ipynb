{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7227,"status":"ok","timestamp":1688366598210,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"REopuI_ItQ-0"},"outputs":[],"source":["import torch\n","import glob\n","import os\n","# glob 결과 숫자 오름차순으로 정리해주는 라이브러리, 기능적으로 필요하지 않았음을 깨달았으나\n","# 정렬 작업이 유지보수를 가정했을 때 충분히 의미 있다고 생각해서 그냥 놔두기로 함\n","import natsort\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch import nn\n","from torchvision import models\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import numpy as np\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25242,"status":"ok","timestamp":1688366623435,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"Bo7Vw5litWYp","outputId":"c663174d-f17b-46a1-c5d4-3e8f30eaae44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import drive.MyDrive.Colab_Notebooks.resnet_datanmodel as datanmodel\n","import drive.MyDrive.Colab_Notebooks.ResNet as ResNet"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1688366623436,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"h7hvx9TS_df9"},"outputs":[],"source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1688366623437,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"mCFV3nEDtQ-8"},"outputs":[],"source":["# 경로 설정, py파일로 변환시 경로는 변경되어야 한다.\n","# local path\n","# path=os.path.abspath('../')\n","# colab path\n","path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/')\n","\n","# Resize: 크기를 224, 224로 맞춘다\n","# ToTensor: 데이터 타입을 Tensor로 만든다. Tensor의 원소는 0~1로 정해진다.(https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)\n","# custom으로 transform를 작성하는 것도 가능하다.\n","transforms=transforms.Compose([\n","    transforms.Resize(size=(224, 224)),\n","    transforms.ToTensor()])"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":152088,"status":"ok","timestamp":1688366775517,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"qVJ1kF6GtQ--"},"outputs":[],"source":["cnd_train=datanmodel.cnd_data(file_path=path, train=True, transforms=transforms)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688366775520,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"gmwCzZu-tQ-_"},"outputs":[],"source":["batch=32\n","cnd_dataloader=DataLoader(cnd_train, batch_size=batch, shuffle=True)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"APH1zcQ90Ubg"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16866,"status":"ok","timestamp":1688366792378,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"uN4V5FULtQ_F","outputId":"84b0543c-d610-4083-d767-73389248f912"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=2, bias=True)\n","  )\n","  (1): Softmax(dim=-1)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-20           [-1, 64, 56, 56]             128\n","             ReLU-21           [-1, 64, 56, 56]               0\n","           Conv2d-22           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-23           [-1, 64, 56, 56]             128\n","             ReLU-24           [-1, 64, 56, 56]               0\n","       BasicBlock-25           [-1, 64, 56, 56]               0\n","           Conv2d-26          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-27          [-1, 128, 28, 28]             256\n","             ReLU-28          [-1, 128, 28, 28]               0\n","           Conv2d-29          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-30          [-1, 128, 28, 28]             256\n","           Conv2d-31          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-36          [-1, 128, 28, 28]             256\n","             ReLU-37          [-1, 128, 28, 28]               0\n","           Conv2d-38          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-39          [-1, 128, 28, 28]             256\n","             ReLU-40          [-1, 128, 28, 28]               0\n","       BasicBlock-41          [-1, 128, 28, 28]               0\n","           Conv2d-42          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-43          [-1, 128, 28, 28]             256\n","             ReLU-44          [-1, 128, 28, 28]               0\n","           Conv2d-45          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-46          [-1, 128, 28, 28]             256\n","             ReLU-47          [-1, 128, 28, 28]               0\n","       BasicBlock-48          [-1, 128, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","       BasicBlock-55          [-1, 128, 28, 28]               0\n","           Conv2d-56          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-57          [-1, 256, 14, 14]             512\n","             ReLU-58          [-1, 256, 14, 14]               0\n","           Conv2d-59          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-60          [-1, 256, 14, 14]             512\n","           Conv2d-61          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-62          [-1, 256, 14, 14]             512\n","             ReLU-63          [-1, 256, 14, 14]               0\n","       BasicBlock-64          [-1, 256, 14, 14]               0\n","           Conv2d-65          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-66          [-1, 256, 14, 14]             512\n","             ReLU-67          [-1, 256, 14, 14]               0\n","           Conv2d-68          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-69          [-1, 256, 14, 14]             512\n","             ReLU-70          [-1, 256, 14, 14]               0\n","       BasicBlock-71          [-1, 256, 14, 14]               0\n","           Conv2d-72          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-73          [-1, 256, 14, 14]             512\n","             ReLU-74          [-1, 256, 14, 14]               0\n","           Conv2d-75          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-76          [-1, 256, 14, 14]             512\n","             ReLU-77          [-1, 256, 14, 14]               0\n","       BasicBlock-78          [-1, 256, 14, 14]               0\n","           Conv2d-79          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-80          [-1, 256, 14, 14]             512\n","             ReLU-81          [-1, 256, 14, 14]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","       BasicBlock-85          [-1, 256, 14, 14]               0\n","           Conv2d-86          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-87          [-1, 256, 14, 14]             512\n","             ReLU-88          [-1, 256, 14, 14]               0\n","           Conv2d-89          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-90          [-1, 256, 14, 14]             512\n","             ReLU-91          [-1, 256, 14, 14]               0\n","       BasicBlock-92          [-1, 256, 14, 14]               0\n","           Conv2d-93          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-94          [-1, 256, 14, 14]             512\n","             ReLU-95          [-1, 256, 14, 14]               0\n","           Conv2d-96          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-97          [-1, 256, 14, 14]             512\n","             ReLU-98          [-1, 256, 14, 14]               0\n","       BasicBlock-99          [-1, 256, 14, 14]               0\n","          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n","     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n","            ReLU-102            [-1, 512, 7, 7]               0\n","          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n","          Conv2d-105            [-1, 512, 7, 7]         131,072\n","     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n","            ReLU-107            [-1, 512, 7, 7]               0\n","      BasicBlock-108            [-1, 512, 7, 7]               0\n","          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n","            ReLU-111            [-1, 512, 7, 7]               0\n","          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n","            ReLU-114            [-1, 512, 7, 7]               0\n","      BasicBlock-115            [-1, 512, 7, 7]               0\n","          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n","            ReLU-118            [-1, 512, 7, 7]               0\n","          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n","            ReLU-121            [-1, 512, 7, 7]               0\n","      BasicBlock-122            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n","          Linear-124                 [-1, 1000]         513,000\n","          ResNet-125                 [-1, 1000]               0\n","         Softmax-126                 [-1, 1000]               0\n","================================================================\n","Total params: 21,797,672\n","Trainable params: 21,797,672\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 96.30\n","Params size (MB): 83.15\n","Estimated Total Size (MB): 180.03\n","----------------------------------------------------------------\n"]}],"source":["# 18 model\n","# train_model=datanmodel.ResNet_compat(blocks_in_model=[2, 2, 2, 2,],\n","#                                      is_18=True).to(device)\n","# 34 model\n","# train_model=datanmodel.ResNet_compat().to(device)\n","# # 50 model\n","# train_model=datanmodel.ResNet_compat(blocks_in_model=[3, 4, 6, 3],\n","#                          layers_in_block=[3, 3, 3, 3],\n","#                          kernel_sizes=[(1,3,1), (1,3,1), (1,3,1), (1,3,1)],\n","#                          channel_sizes=[(64,64,256), (128,128,512), (256,256,1024), (512,512, 2048)]).to(device)\n","###########################################################################\n","# 34 model(torchvision)- summary()는 선언된 클래스를 불러오기 때문에 instance를 변경해도 변경 사항이 반영되지 않는다.\n","train_model=models.resnet34().to(device)\n","\n","# 50 model(torchvision)\n","# train_model=models.resnet50().to(device)\n","\n","# torchvision 불러온 모델의 경우 class=2 조정 및 softmax 추가\n","layer=list(train_model.named_modules())[-1][-1]\n","layer.out_features=2\n","softmax=nn.Softmax(-1)\n","train_model=nn.Sequential(train_model, softmax)\n","###########################################################################\n","print(train_model)\n","summary(train_model, input_size=(3, 224, 224))\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1688366792768,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"bG9T-X7FtQ_G"},"outputs":[],"source":["learning_rate=0.01\n","\n","loss_f= nn.CrossEntropyLoss()\n","# train_model.parameters: 최적화할 대상의 파라미터\n","optimizer = torch.optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1688366792769,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"VeNyDZV-sA9D"},"outputs":[],"source":["log_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_log/')\n","weight_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688366792769,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"aAC_szF7uHgQ"},"outputs":[],"source":["writer=SummaryWriter(log_save_path)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":393,"status":"ok","timestamp":1688366793153,"user":{"displayName":"GD G (왕철면피)","userId":"08503996268701527706"},"user_tz":-540},"id":"0yX1QWtHsu0_","outputId":"d070105d-f225-4713-8775-d1b8de01d97d"},"outputs":[{"output_type":"stream","name":"stdout","text":["처음부터 시작합니다.\n"]}],"source":["# 폴더에 가중치가 있으면 불러온다.\n","# 아래와 같이 코드가 복잡한 이유는 GPU일 때와 CPU일 때의 차이가 있기 때문에 이를 맞춰줘야 했기 때문\n","# 또한 병렬 처리가 된 GPU의 경우 추가로 key를 생성하는데, 비병렬 상황에서는 이를 제거해야 된다.\n","weight_list=natsort.natsorted(glob.glob(weight_save_path+'/*.pth'), reverse=True)\n","\n","if weight_list:\n","  start_epoch=int(weight_list[0].split('_')[-1].split('.')[0])+1\n","  print(f'{start_epoch+1} epoch 부터 시작합니다.')\n","\n","  # GPU 사용 불가시\n","  if device=='cpu':\n","    loaded_weight=torch.load(weight_list[0], map_location=torch.device('cpu'))\n","    if isinstance(train_model,nn.DataParallel):\n","      print('cpu 병렬')\n","    else:\n","      print('cpu 병렬 x')\n","\n","  # GPU 사용 가능시\n","  else:\n","    loaded_weight=torch.load(weight_list[0])\n","    if isinstance(train_model,nn.DataParallel):\n","      print('gpu 병렬')\n","    else:\n","      print('gpu 병렬 x')\n","\n","  model_key=train_model.state_dict().keys()\n","  weight_key=loaded_weight.keys()\n","\n","  diff_list=list()\n","  for key in weight_key:\n","    if key not in model_key:\n","      diff_list.append(key)\n","\n","  for diff_key in diff_list:\n","    del loaded_weight[diff_key]\n","\n","  train_model.load_state_dict(loaded_weight)\n","\n","else:\n","  start_epoch=0\n","  print('처음부터 시작합니다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWooXKQWtQ_H","outputId":"20c8ae1a-fd3a-4185-e72b-5b32dabec803"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss [1, 5](epoch, minibatch):  0.34541107177734376\n","Accuracy [1, 5](epoch, minibatch):  0.4125\n","time taken(per 5 batch): 77.42042660713196\n","Loss [1, 10](epoch, minibatch):  0.34540812492370604\n","Accuracy [1, 10](epoch, minibatch):  0.4625\n","time taken(per 5 batch): 75.69479942321777\n","Loss [1, 15](epoch, minibatch):  0.3454069995880127\n","Accuracy [1, 15](epoch, minibatch):  0.4625\n","time taken(per 5 batch): 74.1530511379242\n","Loss [1, 20](epoch, minibatch):  0.345401873588562\n","Accuracy [1, 20](epoch, minibatch):  0.53125\n","time taken(per 5 batch): 76.31344938278198\n","Loss [1, 25](epoch, minibatch):  0.34539730548858644\n","Accuracy [1, 25](epoch, minibatch):  0.5375\n","time taken(per 5 batch): 75.86320161819458\n","Loss [1, 30](epoch, minibatch):  0.34539199352264405\n","Accuracy [1, 30](epoch, minibatch):  0.55\n","time taken(per 5 batch): 73.52102375030518\n","Loss [1, 35](epoch, minibatch):  0.34538590908050537\n","Accuracy [1, 35](epoch, minibatch):  0.5375\n","time taken(per 5 batch): 77.70650386810303\n","Loss [1, 40](epoch, minibatch):  0.34537267684936523\n","Accuracy [1, 40](epoch, minibatch):  0.5625\n","time taken(per 5 batch): 74.51366376876831\n","Loss [1, 45](epoch, minibatch):  0.34535315990447996\n","Accuracy [1, 45](epoch, minibatch):  0.59375\n","time taken(per 5 batch): 75.52432465553284\n","Loss [1, 50](epoch, minibatch):  0.34533206462860105\n","Accuracy [1, 50](epoch, minibatch):  0.53125\n","time taken(per 5 batch): 75.85265302658081\n","Loss [1, 55](epoch, minibatch):  0.34529771327972414\n","Accuracy [1, 55](epoch, minibatch):  0.44375\n","time taken(per 5 batch): 75.09979581832886\n","Loss [1, 60](epoch, minibatch):  0.34503836154937745\n","Accuracy [1, 60](epoch, minibatch):  0.56875\n","time taken(per 5 batch): 77.83737087249756\n","Loss [1, 65](epoch, minibatch):  0.34373347282409666\n","Accuracy [1, 65](epoch, minibatch):  0.4875\n","time taken(per 5 batch): 77.79123878479004\n","Loss [1, 70](epoch, minibatch):  0.3300511407852173\n","Accuracy [1, 70](epoch, minibatch):  0.51875\n","time taken(per 5 batch): 77.42115879058838\n","Loss [1, 75](epoch, minibatch):  0.319601993560791\n","Accuracy [1, 75](epoch, minibatch):  0.51875\n","time taken(per 5 batch): 77.37290549278259\n","Loss [1, 80](epoch, minibatch):  0.3195363426208496\n","Accuracy [1, 80](epoch, minibatch):  0.51875\n","time taken(per 5 batch): 78.39679837226868\n","Loss [1, 85](epoch, minibatch):  0.3195360565185547\n","Accuracy [1, 85](epoch, minibatch):  0.51875\n","time taken(per 5 batch): 77.29651427268982\n","Loss [1, 90](epoch, minibatch):  0.3198485326766968\n","Accuracy [1, 90](epoch, minibatch):  0.5125\n","time taken(per 5 batch): 77.0598213672638\n","Loss [1, 95](epoch, minibatch):  0.3207860279083252\n","Accuracy [1, 95](epoch, minibatch):  0.49375\n","time taken(per 5 batch): 76.32276940345764\n","Loss [1, 100](epoch, minibatch):  0.3214110374450684\n","Accuracy [1, 100](epoch, minibatch):  0.48125\n","time taken(per 5 batch): 78.72121262550354\n","Loss [1, 105](epoch, minibatch):  0.3198485326766968\n","Accuracy [1, 105](epoch, minibatch):  0.5125\n","time taken(per 5 batch): 77.42823815345764\n","Loss [1, 110](epoch, minibatch):  0.3254735279083252\n","Accuracy [1, 110](epoch, minibatch):  0.4\n","time taken(per 5 batch): 86.3660500049591\n","Loss [1, 115](epoch, minibatch):  0.31734853744506836\n","Accuracy [1, 115](epoch, minibatch):  0.5625\n","time taken(per 5 batch): 76.61727166175842\n","Loss [1, 120](epoch, minibatch):  0.31984854221343995\n","Accuracy [1, 120](epoch, minibatch):  0.5125\n","time taken(per 5 batch): 77.3502037525177\n","Loss [1, 125](epoch, minibatch):  0.3207860422134399\n","Accuracy [1, 125](epoch, minibatch):  0.49375\n","time taken(per 5 batch): 76.47151398658752\n","Loss [1, 130](epoch, minibatch):  0.31766104221343994\n","Accuracy [1, 130](epoch, minibatch):  0.55625\n","time taken(per 5 batch): 78.69328188896179\n","Loss [1, 135](epoch, minibatch):  0.31891104221343997\n","Accuracy [1, 135](epoch, minibatch):  0.53125\n","time taken(per 5 batch): 76.96621799468994\n","Loss [1, 140](epoch, minibatch):  0.3204735279083252\n","Accuracy [1, 140](epoch, minibatch):  0.5\n","time taken(per 5 batch): 74.40689253807068\n","Loss [1, 145](epoch, minibatch):  0.3214110279083252\n","Accuracy [1, 145](epoch, minibatch):  0.48125\n","time taken(per 5 batch): 79.10498571395874\n","Loss [1, 150](epoch, minibatch):  0.3214110326766968\n","Accuracy [1, 150](epoch, minibatch):  0.48125\n","time taken(per 5 batch): 75.69886088371277\n","Loss [1, 155](epoch, minibatch):  0.3189110326766968\n","Accuracy [1, 155](epoch, minibatch):  0.53125\n","time taken(per 5 batch): 78.17834091186523\n","Loss [1, 160](epoch, minibatch):  0.3204735469818115\n","Accuracy [1, 160](epoch, minibatch):  0.5\n","time taken(per 5 batch): 75.05449080467224\n","Loss [1, 165](epoch, minibatch):  0.31797353744506834\n","Accuracy [1, 165](epoch, minibatch):  0.55\n","time taken(per 5 batch): 77.7807981967926\n","Loss [1, 170](epoch, minibatch):  0.32141104221343997\n","Accuracy [1, 170](epoch, minibatch):  0.48125\n","time taken(per 5 batch): 76.61286163330078\n","Loss [1, 175](epoch, minibatch):  0.3220360279083252\n","Accuracy [1, 175](epoch, minibatch):  0.46875\n","time taken(per 5 batch): 76.47842907905579\n","Loss [1, 180](epoch, minibatch):  0.32266103744506835\n","Accuracy [1, 180](epoch, minibatch):  0.45625\n","time taken(per 5 batch): 77.71868681907654\n","Loss [1, 185](epoch, minibatch):  0.31891104221343997\n","Accuracy [1, 185](epoch, minibatch):  0.53125\n","time taken(per 5 batch): 76.07425141334534\n","Loss [1, 190](epoch, minibatch):  0.31953603744506837\n","Accuracy [1, 190](epoch, minibatch):  0.51875\n","time taken(per 5 batch): 76.67140007019043\n","Loss [1, 195](epoch, minibatch):  0.3214110374450684\n","Accuracy [1, 195](epoch, minibatch):  0.48125\n","time taken(per 5 batch): 75.47739744186401\n","Loss [1, 200](epoch, minibatch):  0.3201610279083252\n","Accuracy [1, 200](epoch, minibatch):  0.50625\n","time taken(per 5 batch): 77.23489260673523\n","Loss [1, 205](epoch, minibatch):  0.3189110326766968\n","Accuracy [1, 205](epoch, minibatch):  0.53125\n","time taken(per 5 batch): 78.41610765457153\n","Loss [1, 210](epoch, minibatch):  0.32047353744506835\n","Accuracy [1, 210](epoch, minibatch):  0.5\n","time taken(per 5 batch): 79.23008155822754\n","Loss [1, 215](epoch, minibatch):  0.32016103744506835\n","Accuracy [1, 215](epoch, minibatch):  0.50625\n","time taken(per 5 batch): 83.64973187446594\n","Loss [1, 220](epoch, minibatch):  0.3248485326766968\n","Accuracy [1, 220](epoch, minibatch):  0.4125\n","time taken(per 5 batch): 78.57812571525574\n","Loss [1, 225](epoch, minibatch):  0.32047354221343993\n","Accuracy [1, 225](epoch, minibatch):  0.5\n","time taken(per 5 batch): 78.02323651313782\n","Loss [1, 230](epoch, minibatch):  0.32203603744506837\n","Accuracy [1, 230](epoch, minibatch):  0.46875\n","time taken(per 5 batch): 79.52333688735962\n","Loss [1, 235](epoch, minibatch):  0.32016103267669677\n","Accuracy [1, 235](epoch, minibatch):  0.50625\n","time taken(per 5 batch): 78.19926357269287\n","Loss [1, 240](epoch, minibatch):  0.32047353267669676\n","Accuracy [1, 240](epoch, minibatch):  0.5\n","time taken(per 5 batch): 78.43064141273499\n","Loss [1, 245](epoch, minibatch):  0.31797354221343993\n","Accuracy [1, 245](epoch, minibatch):  0.55\n","time taken(per 5 batch): 75.80673480033875\n","Loss [1, 250](epoch, minibatch):  0.3210985326766968\n","Accuracy [1, 250](epoch, minibatch):  0.4875\n","time taken(per 5 batch): 77.14930820465088\n","Loss [1, 255](epoch, minibatch):  0.3217235374450684\n","Accuracy [1, 255](epoch, minibatch):  0.475\n","time taken(per 5 batch): 76.76046919822693\n","Loss [1, 260](epoch, minibatch):  0.31734854698181153\n","Accuracy [1, 260](epoch, minibatch):  0.5625\n","time taken(per 5 batch): 75.03563046455383\n","Loss [1, 265](epoch, minibatch):  0.32016103744506835\n","Accuracy [1, 265](epoch, minibatch):  0.50625\n","time taken(per 5 batch): 76.34287428855896\n","Loss [1, 270](epoch, minibatch):  0.31797353744506834\n","Accuracy [1, 270](epoch, minibatch):  0.55\n","time taken(per 5 batch): 79.47471618652344\n","Loss [1, 275](epoch, minibatch):  0.3198485326766968\n","Accuracy [1, 275](epoch, minibatch):  0.5125\n","time taken(per 5 batch): 79.63273882865906\n","Loss [1, 280](epoch, minibatch):  0.32203603744506837\n","Accuracy [1, 280](epoch, minibatch):  0.46875\n","time taken(per 5 batch): 76.39967942237854\n","Loss [1, 285](epoch, minibatch):  0.31953604698181154\n","Accuracy [1, 285](epoch, minibatch):  0.51875\n","time taken(per 5 batch): 76.43376612663269\n","Loss [1, 290](epoch, minibatch):  0.3210985326766968\n","Accuracy [1, 290](epoch, minibatch):  0.4875\n","time taken(per 5 batch): 81.19792461395264\n","Loss [1, 295](epoch, minibatch):  0.32047353744506835\n","Accuracy [1, 295](epoch, minibatch):  0.5\n","time taken(per 5 batch): 92.86285257339478\n","Loss [1, 300](epoch, minibatch):  0.32266103744506835\n","Accuracy [1, 300](epoch, minibatch):  0.45625\n","time taken(per 5 batch): 95.58775281906128\n","Loss [1, 305](epoch, minibatch):  0.32047353744506835\n","Accuracy [1, 305](epoch, minibatch):  0.5\n","time taken(per 5 batch): 89.12912654876709\n","Loss [1, 310](epoch, minibatch):  0.32297353267669676\n","Accuracy [1, 310](epoch, minibatch):  0.45\n","time taken(per 5 batch): 85.26033210754395\n","Loss [1, 315](epoch, minibatch):  0.3217235374450684\n","Accuracy [1, 315](epoch, minibatch):  0.475\n","time taken(per 5 batch): 82.06196284294128\n","Loss [1, 320](epoch, minibatch):  0.31984854221343995\n","Accuracy [1, 320](epoch, minibatch):  0.5125\n","time taken(per 5 batch): 80.33729410171509\n","Loss [1, 325](epoch, minibatch):  0.32109853744506833\n","Accuracy [1, 325](epoch, minibatch):  0.4875\n","time taken(per 5 batch): 80.30613207817078\n","Loss [1, 330](epoch, minibatch):  0.32297354221343993\n","Accuracy [1, 330](epoch, minibatch):  0.45\n","time taken(per 5 batch): 78.51004481315613\n","Loss [1, 335](epoch, minibatch):  0.3182860469818115\n","Accuracy [1, 335](epoch, minibatch):  0.54375\n","time taken(per 5 batch): 81.85686326026917\n","Loss [1, 340](epoch, minibatch):  0.32297353267669676\n","Accuracy [1, 340](epoch, minibatch):  0.45\n","time taken(per 5 batch): 84.73977255821228\n","Loss [1, 345](epoch, minibatch):  0.31984853744506836\n","Accuracy [1, 345](epoch, minibatch):  0.5125\n","time taken(per 5 batch): 98.27961874008179\n","Loss [1, 350](epoch, minibatch):  0.3210985326766968\n","Accuracy [1, 350](epoch, minibatch):  0.4875\n","time taken(per 5 batch): 77.4903609752655\n","Loss [1, 355](epoch, minibatch):  0.32047353267669676\n","Accuracy [1, 355](epoch, minibatch):  0.5\n","time taken(per 5 batch): 77.87970638275146\n","Loss [1, 360](epoch, minibatch):  0.3192235326766968\n","Accuracy [1, 360](epoch, minibatch):  0.525\n","time taken(per 5 batch): 77.79364371299744\n","Loss [1, 365](epoch, minibatch):  0.3239110279083252\n","Accuracy [1, 365](epoch, minibatch):  0.43125\n","time taken(per 5 batch): 83.91509866714478\n"]}],"source":["# dogs 11285, 8730, 11675 3588, 5604(not dog), 11853, 2877, 6318, 9078(channel 4), 11410 /3588와 5604가 중복해서 나옴. 특정 데이터 문제일 가능성이 높아짐\n","# cats 8470, 5686, 9778, 2877, 7276, 11935, 5370\n","# 위 문제는 비트 수준(bit-depth)문제로 발생한 것이며, 이미 해결함\n","\n","EPOCHS=40\n","\n","for epoch in range(start_epoch, EPOCHS):\n","    # running loss: 5batch동안 loss 누적값\n","    running_loss=0\n","    running_acc=0\n","\n","    # epoch_total_loss: 1 epoch에서 발생한 loss 누적값, 750(1 epoch batch수)을 나눠서 평균 loss값을 구하는데 사용할 예정\n","    epoch_total_loss=0\n","    epoch_total_acc=0\n","    start_time=time.time()\n","\n","\n","    for i, inp in enumerate(cnd_dataloader):\n","\n","        input, label= inp\n","        input, label= input.to(device), torch.Tensor(label).to(device)\n","        # 모든 gradient를 0으로 설정, 이렇게 하지 않으면 이전 loop의 gradient값이 그대로 남아있어 제대로 학습이 되지 않는다.\n","        optimizer.zero_grad()\n","\n","        # train_model을 태운 다음 loss를 계산한다.\n","        output= train_model(input)\n","        loss= loss_f(output, label)\n","\n","        # accuracy를 계산한다.\n","        correct=0\n","        for t in zip(output.tolist(), label.tolist()):\n","          if t[0][0] >= 0.5:\n","              ans=0\n","          else:\n","              ans=1\n","          if ans==t[1]:\n","            correct+=1\n","          else:\n","            pass\n","\n","        # loss.backward()로 gradient를 계산하고\n","        # optimizer를 사용하여 반영한다.\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss+=loss.item()\n","        running_acc+=correct\n","\n","        if i%5 == 4 and i>0:\n","            end_time=time.time()\n","\n","            print(f'Loss [{epoch+1}, {i+1}](epoch, minibatch): ', running_loss/100)\n","            print(f'Accuracy [{epoch+1}, {i+1}](epoch, minibatch): ', running_acc/(batch*5))\n","            print('time taken(per 5 batch):', end_time-start_time)\n","            start_time=end_time\n","            epoch_total_loss+=running_loss\n","            epoch_total_acc+=running_acc\n","            running_loss=0.0\n","            running_acc=0\n","    # resnet 34 저장\n","    torch.save(train_model.state_dict(), os.path.join(weight_save_path, f'model_34_weights_{epoch}.pth'))\n","    # resnet 50 저장\n","    # torch.save(train_model.state_dict(), os.path.join(weight_save_path, f'model_50_weights_{epoch}.pth'))\n","    writer.add_scalar(\"Loss / epoch \", epoch_total_loss/len(cnd_train), epoch)\n","    writer.add_scalar(\"Accuracy / epoch\", epoch_total_acc/len(cnd_train), epoch)\n","\n","\n","writer.close()\n"]},{"cell_type":"markdown","metadata":{"id":"3e7SHuwRlMpl"},"source":["본문 끝, 테스트 코드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXKN5Oh_5wKz"},"outputs":[],"source":["raise Exception(\"에러 메시지\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9h3h39_8ENw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YhmP7Nolqnr"},"outputs":[],"source":["# 34 model\n","model_34=datanmodel.ResNet_compat().to(device)\n","# # 50 model\n","model_50=datanmodel.ResNet_compat(input_shape=(3, 224, 224),\n","                        blocks_in_model=[3, 4, 6, 3],\n","                         layers_in_block=[3, 3, 3, 3],\n","                         kernel_sizes=[(1,3,1), (1,3,1), (1,3,1), (1,3,1)],\n","                         channel_sizes=[(64,64,256), (128,128,512), (256,256,1024), (512,512, 2048)]).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEzF3SLUmWf8"},"outputs":[],"source":["t_p= sum(p.numel() for p in model_34.parameters())\n","print(t_p)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7pkplzDqFxF"},"outputs":[],"source":["t_p2= sum(p.numel() for p in model_50.parameters())\n","print(t_p2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eoGj8hEhq4el"},"outputs":[],"source":["import torch\n","import torchvision.models as models\n","\n","# ResNet-50 모델 인스턴스 생성\n","model = models.resnet50()\n","\n","# 모델의 파라미터 개수 계산\n","total_params = sum(p.numel() for p in model.parameters())\n","print(\"Total parameters:\", total_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEn1Egunr4ox"},"outputs":[],"source":["# ResNet-50 모델 인스턴스 생성\n","model = models.resnet34()\n","\n","# 모델의 파라미터 개수 계산\n","total_params = sum(p.numel() for p in model.parameters())\n","print(\"Total parameters:\", total_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6rPbCvbtWK1"},"outputs":[],"source":["# ResNet-50 모델 인스턴스 생성\n","model = models.resnet18()\n","\n","# 모델의 파라미터 개수 계산\n","total_params = sum(p.numel() for p in model.parameters())\n","print(\"Total parameters:\", total_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyVwivjetpLb"},"outputs":[],"source":["train_model=datanmodel.ResNet_compat(blocks_in_model=[3, 4, 6, 3],\n","                         layers_in_block=[3, 3, 3, 3],\n","                         kernel_sizes=[(1,3,1), (1,3,1), (1,3,1), (1,3,1)],\n","                         channel_sizes=[(64,64,256), (128,128,512), (256,256,1024), (512,512, 2048)]).to(device)\n","\n","t_p3= sum(p.numel() for p in train_model.parameters())\n","print(t_p3)"]},{"cell_type":"code","source":["model_50=models.resnet50()\n","summary(model_50, input_size=(3, 224, 224))"],"metadata":{"id":"BjIRqmWnP7AT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.models as models\n","from torchsummary import summary\n","\n","# ResNet-50 모델 불러오기\n","model = models.resnet50().to(device)\n","\n","# 모델 요약 정보 출력\n","summary(model, (3, 224, 224))  # 입력 이미지 크기에 맞게 설정"],"metadata":{"id":"hL9yZb6KlZIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_34 = models.resnet34().to(device)\n","for i in model_34.named_modules():\n","  print(i)"],"metadata":{"id":"yuCwT4ERo6wg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["layer=list(model_34.named_modules())[-1][-1]\n","layer.out_features=2\n","\n","print(model_34)\n","\n"],"metadata":{"id":"ceoN17r8X23R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H6KJquh2Ymfl"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}