{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "REopuI_ItQ-0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import glob\n",
        "import os\n",
        "# glob 결과 숫자 오름차순으로 정리해주는 라이브러리, 기능적으로 필요하지 않았음을 깨달았으나\n",
        "# 정렬 작업이 유지보수를 가정했을 때 충분히 의미 있다고 생각해서 그냥 놔두기로 함\n",
        "import natsort\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import drive.MyDrive.Colab_Notebooks.resnet_datanmodel as datanmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo7Vw5litWYp",
        "outputId": "60e4e78e-d552-405e-ee5e-5922e2d63c07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "h7hvx9TS_df9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mCFV3nEDtQ-8"
      },
      "outputs": [],
      "source": [
        "# 경로 설정, py파일로 변환시 경로는 변경되어야 한다.\n",
        "# local path\n",
        "# path=os.path.abspath('../')\n",
        "# colab path\n",
        "path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/')\n",
        "\n",
        "# Resize: 크기를 224, 224로 맞춘다\n",
        "# ToTensor: 데이터 타입을 Tensor로 만든다. Tensor의 원소는 0~1로 정해진다.(https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)\n",
        "# custom으로 transform를 작성하는 것도 가능하다.\n",
        "transforms=transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qVJ1kF6GtQ--"
      },
      "outputs": [],
      "source": [
        "cnd_train=datanmodel.cnd_data(file_path=path, train=True, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gmwCzZu-tQ-_"
      },
      "outputs": [],
      "source": [
        "batch=32\n",
        "cnd_dataloader=DataLoader(cnd_train, batch_size=batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a81U4uKFtQ_A"
      },
      "outputs": [],
      "source": [
        "# resnet34나 50이나 조금씩 원문에서 주장하는 model을 수정한 듯한 흔적이 보인다.\n",
        "# 하지만 지금은 resnet 원문의 것을 구현하는 입장이기 때문에\n",
        "# 모델 참조를 하다 원문과 다른 부분이 있다면 무시하고 원문대로 한다.\n",
        "# resnet34_preset=models.resnet34()\n",
        "# summary(resnet34_preset, input_size=(3, 224, 224))\n",
        "# print(resnet34_preset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5vTLO01etQ_D"
      },
      "outputs": [],
      "source": [
        "# resnet50_preset=models.resnet50()\n",
        "# summary(resnet50_preset, input_size=(3, 224, 224))\n",
        "# print(resnet50_preset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uN4V5FULtQ_F"
      },
      "outputs": [],
      "source": [
        "train_model=datanmodel.ResNet_compat().to(device)\n",
        "# summary(train_model, input_size=(3, 224, 224))\n",
        "# print(train_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bG9T-X7FtQ_G"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.01\n",
        "\n",
        "loss_f= nn.CrossEntropyLoss()\n",
        "# train_model.parameters: 최적화할 대상의 파라미터\n",
        "# lr=learning_rate\n",
        "optimizer = torch.optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_log/')\n",
        "weight_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/')"
      ],
      "metadata": {
        "id": "VeNyDZV-sA9D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer=SummaryWriter(log_save_path)"
      ],
      "metadata": {
        "id": "aAC_szF7uHgQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 폴더에 가중치가 있으면 불러온다.\n",
        "# 아래와 같이 코드가 복잡한 이유는 GPU일 때와 CPU일 때의 차이가 있기 때문에 이를 맞춰줘야 했기 때문\n",
        "# 또한 병렬 처리가 된 GPU의 경우 추가로 key를 생성하는데, 비병렬 상황에서는 이를 제거해야 된다.\n",
        "weight_list=natsort.natsorted(glob.glob(weight_save_path+'/*.pth'), reverse=True)\n",
        "\n",
        "if weight_list:\n",
        "  start_epoch=int(weight_list[0].split('_')[-1].split('.')[0])+1\n",
        "  print(f'{start_epoch+1} epoch 부터 시작합니다.')\n",
        "\n",
        "  # GPU 사용 불가시\n",
        "  if device=='cpu':\n",
        "    loaded_weight=torch.load(weight_list[0], map_location=torch.device('cpu'))\n",
        "    if isinstance(train_model,nn.DataParallel):\n",
        "      print('cpu 병렬')\n",
        "    else:\n",
        "      print('cpu 병렬 x')\n",
        "\n",
        "  # GPU 사용 가능시\n",
        "  else:\n",
        "    loaded_weight=torch.load(weight_list[0])\n",
        "    if isinstance(train_model,nn.DataParallel):\n",
        "      print('gpu 병렬')\n",
        "    else:\n",
        "      print('gpu 병렬 x')\n",
        "\n",
        "  model_key=train_model.state_dict().keys()\n",
        "  weight_key=loaded_weight.keys()\n",
        "\n",
        "  diff_list=list()\n",
        "  for key in weight_key:\n",
        "    if key not in model_key:\n",
        "      diff_list.append(key)\n",
        "\n",
        "  for diff_key in diff_list:\n",
        "    del loaded_weight[diff_key]\n",
        "\n",
        "  train_model.load_state_dict(loaded_weight)\n",
        "\n",
        "else:\n",
        "  start_epoch=0\n",
        "  print('처음부터 시작합니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yX1QWtHsu0_",
        "outputId": "a4e264c6-eb44-4c93-9585-4b60fbb82dec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 epoch 부터 시작합니다.\n",
            "gpu 병렬 x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWooXKQWtQ_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8470bff9-792d-480a-9320-2d3b3c079669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss [40, 5](epoch, minibatch):  0.016976864635944368\n",
            "Accuracy [40, 5](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 135.1524269580841\n",
            "Loss [40, 10](epoch, minibatch):  0.017187028527259826\n",
            "Accuracy [40, 10](epoch, minibatch):  0.96875\n",
            "time taken(per 5 batch): 126.47040438652039\n",
            "Loss [40, 15](epoch, minibatch):  0.01630682796239853\n",
            "Accuracy [40, 15](epoch, minibatch):  0.9875\n",
            "time taken(per 5 batch): 127.3164496421814\n",
            "Loss [40, 20](epoch, minibatch):  0.018357443511486052\n",
            "Accuracy [40, 20](epoch, minibatch):  0.94375\n",
            "time taken(per 5 batch): 126.85471320152283\n",
            "Loss [40, 25](epoch, minibatch):  0.016971471905708312\n",
            "Accuracy [40, 25](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 123.07344603538513\n",
            "Loss [40, 30](epoch, minibatch):  0.01633536398410797\n",
            "Accuracy [40, 30](epoch, minibatch):  0.9875\n",
            "time taken(per 5 batch): 127.36613249778748\n",
            "Loss [40, 35](epoch, minibatch):  0.01701154887676239\n",
            "Accuracy [40, 35](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 127.37074947357178\n",
            "Loss [40, 40](epoch, minibatch):  0.01673202097415924\n",
            "Accuracy [40, 40](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 123.84814882278442\n",
            "Loss [40, 45](epoch, minibatch):  0.016050989925861358\n",
            "Accuracy [40, 45](epoch, minibatch):  0.99375\n",
            "time taken(per 5 batch): 128.0016016960144\n",
            "Loss [40, 50](epoch, minibatch):  0.016725199818611144\n",
            "Accuracy [40, 50](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 122.54012894630432\n",
            "Loss [40, 55](epoch, minibatch):  0.016450342535972596\n",
            "Accuracy [40, 55](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 124.04524683952332\n",
            "Loss [40, 60](epoch, minibatch):  0.01705404758453369\n",
            "Accuracy [40, 60](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 124.6259388923645\n",
            "Loss [40, 65](epoch, minibatch):  0.016277553141117097\n",
            "Accuracy [40, 65](epoch, minibatch):  0.9875\n",
            "time taken(per 5 batch): 122.39948511123657\n",
            "Loss [40, 70](epoch, minibatch):  0.017610568404197693\n",
            "Accuracy [40, 70](epoch, minibatch):  0.9625\n",
            "time taken(per 5 batch): 123.3916506767273\n",
            "Loss [40, 75](epoch, minibatch):  0.017371010184288025\n",
            "Accuracy [40, 75](epoch, minibatch):  0.9625\n",
            "time taken(per 5 batch): 125.22173142433167\n",
            "Loss [40, 80](epoch, minibatch):  0.01606816977262497\n",
            "Accuracy [40, 80](epoch, minibatch):  0.99375\n",
            "time taken(per 5 batch): 123.51662468910217\n",
            "Loss [40, 85](epoch, minibatch):  0.01696670025587082\n",
            "Accuracy [40, 85](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 124.8226637840271\n",
            "Loss [40, 90](epoch, minibatch):  0.016796168684959412\n",
            "Accuracy [40, 90](epoch, minibatch):  0.98125\n",
            "time taken(per 5 batch): 126.42934823036194\n",
            "Loss [40, 95](epoch, minibatch):  0.0165340194106102\n",
            "Accuracy [40, 95](epoch, minibatch):  0.9875\n",
            "time taken(per 5 batch): 123.9709837436676\n",
            "Loss [40, 100](epoch, minibatch):  0.01670618325471878\n",
            "Accuracy [40, 100](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 124.67780947685242\n",
            "Loss [40, 105](epoch, minibatch):  0.016025309562683106\n",
            "Accuracy [40, 105](epoch, minibatch):  0.99375\n",
            "time taken(per 5 batch): 122.75371742248535\n",
            "Loss [40, 110](epoch, minibatch):  0.016187495589256286\n",
            "Accuracy [40, 110](epoch, minibatch):  0.9875\n",
            "time taken(per 5 batch): 124.86983895301819\n",
            "Loss [40, 115](epoch, minibatch):  0.017063320875167848\n",
            "Accuracy [40, 115](epoch, minibatch):  0.96875\n",
            "time taken(per 5 batch): 122.69437432289124\n",
            "Loss [40, 120](epoch, minibatch):  0.01595510631799698\n",
            "Accuracy [40, 120](epoch, minibatch):  0.99375\n",
            "time taken(per 5 batch): 127.40669703483582\n",
            "Loss [40, 125](epoch, minibatch):  0.016465072929859163\n",
            "Accuracy [40, 125](epoch, minibatch):  0.9875\n",
            "time taken(per 5 batch): 127.12526273727417\n",
            "Loss [40, 130](epoch, minibatch):  0.017833475172519684\n",
            "Accuracy [40, 130](epoch, minibatch):  0.95\n",
            "time taken(per 5 batch): 123.90466952323914\n",
            "Loss [40, 135](epoch, minibatch):  0.016787087619304655\n",
            "Accuracy [40, 135](epoch, minibatch):  0.98125\n",
            "time taken(per 5 batch): 126.7119574546814\n",
            "Loss [40, 140](epoch, minibatch):  0.01770214945077896\n",
            "Accuracy [40, 140](epoch, minibatch):  0.9625\n",
            "time taken(per 5 batch): 131.3733389377594\n",
            "Loss [40, 145](epoch, minibatch):  0.016425660848617553\n",
            "Accuracy [40, 145](epoch, minibatch):  0.98125\n",
            "time taken(per 5 batch): 125.00197410583496\n",
            "Loss [40, 150](epoch, minibatch):  0.018537935316562653\n",
            "Accuracy [40, 150](epoch, minibatch):  0.93125\n",
            "time taken(per 5 batch): 124.1232533454895\n",
            "Loss [40, 155](epoch, minibatch):  0.01675761044025421\n",
            "Accuracy [40, 155](epoch, minibatch):  0.975\n",
            "time taken(per 5 batch): 124.24587440490723\n"
          ]
        }
      ],
      "source": [
        "# dogs 11285, 8730, 11675 3588, 5604(not dog), 11853, 2877, 6318, 9078(channel 4), 11410 /3588와 5604가 중복해서 나옴. 특정 데이터 문제일 가능성이 높아짐\n",
        "# cats 8470, 5686, 9778, 2877, 7276, 11935, 5370\n",
        "# 위 문제는 비트 수준(bit-depth)문제로 발생한 것이며, 이미 해결함\n",
        "\n",
        "EPOCHS=60\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    # running loss: 5batch동안 loss 누적값\n",
        "    running_loss=0\n",
        "    running_acc=0\n",
        "\n",
        "    # epoch_total_loss: 1 epoch에서 발생한 loss 누적값, 750(1 epoch batch수)을 나눠서 평균 loss값을 구하는데 사용할 예정\n",
        "    epoch_total_loss=0\n",
        "    epoch_total_acc=0\n",
        "    start_time=time.time()\n",
        "\n",
        "\n",
        "    for i, inp in enumerate(cnd_dataloader):\n",
        "\n",
        "        input, label= inp\n",
        "        input, label= input.to(device), torch.Tensor(label).to(device)\n",
        "        # 모든 gradient를 0으로 설정, 이렇게 하지 않으면 이전 loop의 gradient값이 그대로 남아있어 제대로 학습이 되지 않는다.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # train_model을 태운 다음 loss를 계산한다.\n",
        "        output= train_model(input)\n",
        "        loss= loss_f(output, label)\n",
        "\n",
        "        # accuracy를 계산한다.\n",
        "        correct=0\n",
        "        for t in zip(output.tolist(), label.tolist()):\n",
        "          if t[0][0] >= 0.5:\n",
        "              ans=0\n",
        "          else:\n",
        "              ans=1\n",
        "          if ans==t[1]:\n",
        "            correct+=1\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "        # loss.backward()로 gradient를 계산하고\n",
        "        # optimizer를 사용하여 반영한다.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss+=loss.item()\n",
        "        running_acc+=correct\n",
        "\n",
        "        if i%5 == 4 and i>0:\n",
        "            end_time=time.time()\n",
        "\n",
        "            print(f'Loss [{epoch+1}, {i+1}](epoch, minibatch): ', running_loss/100)\n",
        "            print(f'Accuracy [{epoch+1}, {i+1}](epoch, minibatch): ', running_acc/(batch*5))\n",
        "            print('time taken(per 5 batch):', end_time-start_time)\n",
        "            start_time=end_time\n",
        "            epoch_total_loss+=running_loss\n",
        "            epoch_total_acc+=running_acc\n",
        "            running_loss=0.0\n",
        "            running_acc=0\n",
        "\n",
        "    torch.save(train_model.state_dict(), os.path.join(weight_save_path, f'model_weights_{epoch}.pth'))\n",
        "    writer.add_scalar(\"Loss / epoch \", epoch_total_loss/len(cnd_train), epoch)\n",
        "    writer.add_scalar(\"Accuracy / epoch\", epoch_total_acc/len(cnd_train), epoch)\n",
        "\n",
        "\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래는 가중치 확인"
      ],
      "metadata": {
        "id": "3e7SHuwRlMpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception(\"에러 메시지\")"
      ],
      "metadata": {
        "id": "cXKN5Oh_5wKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 불가시\n",
        "if device=='cpu':\n",
        "  if isinstance(train_model,nn.DataParallel):\n",
        "    print('cpu 병렬')\n",
        "  else:\n",
        "\n",
        "    print('cpu 병렬 x')\n",
        "\n",
        "# GPU 사용 가능시\n",
        "else:\n",
        "  if isinstance(train_model,nn.DataParallel):\n",
        "    print('gpu 병렬')\n",
        "  else:\n",
        "    print('gpu 병렬 x')"
      ],
      "metadata": {
        "id": "m3DK2cmiFDES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4EYgxyItQ_J"
      },
      "outputs": [],
      "source": [
        "weight_save_path=os.path.abspath('./drive/MyDrive/Colab_Notebooks/resnet/resnet_pth/')\n",
        "weight_list=natsort.natsorted(glob.glob(weight_save_path+'/*.pth'), reverse=True)\n",
        "loaded_weight=torch.load(weight_list[0], map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=train_model.state_dict().keys()\n",
        "weight=loaded_weight.keys()\n",
        "\n",
        "# model_keys=set(train_model.state_dict().keys())\n",
        "# weight_keys=set(loaded_weight.keys())\n",
        "\n",
        "for key in weight:\n",
        "  if key not in model:\n",
        "    print(key)"
      ],
      "metadata": {
        "id": "XsmXwSCK7uaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9h3h39_8ENw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(loaded_weight.keys())"
      ],
      "metadata": {
        "id": "_YhmP7Nolqnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_model.state_dict().keys())"
      ],
      "metadata": {
        "id": "VEzF3SLUmWf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'reduce.weight' in loaded_weight.keys():"
      ],
      "metadata": {
        "id": "n7pkplzDqFxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del loaded_weight['reduce.bias']"
      ],
      "metadata": {
        "id": "eoGj8hEhq4el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del loaded_weight['reduce.weight']"
      ],
      "metadata": {
        "id": "MEn1Egunr4ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model.load_state_dict(loaded_weight)"
      ],
      "metadata": {
        "id": "O6rPbCvbtWK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyVwivjetpLb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}